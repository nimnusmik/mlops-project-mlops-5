# 영화 평점 예측 서비스 MLOps 프로젝트 PRD

## **🎬 프로젝트명**

**IMDB·TMDB 데이터를 활용한 영화 평점 예측 서비스 개발 및 MLOps 파이프라인 구축**

---

## **🎯 프로젝트 목적 및 배경**

- **목표:**
    - IMDB, TMDB 등 다양한 공개 영화 데이터를 활용해
        
        **영화 평점 예측 서비스를 개발**하고,
        
        **컨테이너 기반 MLOps 파이프라인의 설계·구현·자동화**까지
        
        실전 중심으로 구현.
        
- **배경:**
    - MLOps 핵심 실습:
        - **모델 코드 모듈화, 데이터/피처 엔지니어링,
        컨테이너 기반 학습·서빙·API 배포,
        파이프라인 자동화** 경험 내재화.
    - 전체 파이프라인 중 **관심 컴포넌트 1개 이상 직접 구현** 및
        
        실무·대회 수준 자동화 구성.
        

---

## **📌 프로젝트 범위 및 방향**

- **주요 데이터:**
    - **IMDB, TMDB API 및 데이터셋** 병행 활용
        
        (메타데이터/평점/리뷰/장르 등 다양한 구조)
        
- **MLOps 목표:**
    - 로컬 개발 모델을 컨테이너화해 API로 서빙
    - **Airflow 기반 데이터/피처 파이프라인,
    Feast Feature Store, MLflow 실험관리/레지스트리,
    FastAPI 서빙, GitHub Actions 기반 CI/CD,
    전체 모니터링 및 자동화** 구성
    - **자동화/DevOps/운영관리까지 실전 완성도에 중점**
- **산출물:**
    - 최종 발표자료(PDF),
        
        소스코드(깃허브 저장소, 이슈/프로젝트 기반 일정/업무 관리),
        
        팀 역할·일정·기여내역 등 전 과정의 산출물 투명 관리
        
    - **모델 개발 구체 성능 자체는 평가 대상 아님**
        
        (모델 API 및 파이프라인 구현·자동화·운영 중심)
        

---

## **🏆 주요 평가 기준 반영**

- 아키텍처 설계 타당성, 확장성, 컴포넌트 분리
- 컨테이너/Docker/자동화 완성도, API 서빙 흐름
- 코드 품질(일관성, 중복최소화, 모듈화)
- Git 협업(이슈/프로젝트/코드리뷰)
- 발표력/계획/일정 관리(깃허브 이슈/프로젝트로 진행)
- 팀 내 역할 분담, 기여 내역

---

## 👥 역할 분담

### **1️⃣ 인력 배분**

- **데이터 전처리 2명**
    - TMDB, IMDB **각각 1명씩** 맡아서 동시에 데이터 수집/정제/EDA 진행
    - 또는 **API/Raw 데이터 파싱 + DB적재(1명)**,
        
        **피처 가공/스키마 설계/정제(1명)**로 나눌 수도 있음
        
- **데이터 분석+모델링 1명**
    - 베이스라인 모델링, 피처 엔지니어링, MLflow 연동
- **자동화 파이프라인+CI/CD 1명**
    - Airflow DAG, Docker, GitHub Actions 자동화 전체 설계/구현

---

### **2️⃣ 동시작업 전략**

**데이터 전처리팀이 tmdb, imdb의 전체 데이터 받아 컬럼/피처(최종 스키마) 정의**

**이 팀이 데이터 표준(컬럼, 타입, Null처리 등) 확정/가이드 제공**

→ 전체 파이프라인의 기준이 됨.

**하지만, 파이프라인/모델링팀은 '완성된 데이터'를 기다리면 시간 낭비**

- **임시로 "Raw 데이터" 기준으로 파이프라인, 모델 코드, DAG 구조 먼저 구축**
- 예:
    - **자동화 파트:** TMDB/IMDB API에서 'raw' JSON 받아 PostgreSQL/S3에 적재,
        
        임시로 '임의 컬럼'으로 데이터 플로우 구성
        
    - **모델링 파트:** 'raw' 데이터 기준으로 EDA/베이스라인 코드부터 만들고,
        
        추후 **최종 컬럼/피처**로 코드만 일부 교체
        

---

### **3️⃣ 팀별 실무 동시 진행 방식**

1. **데이터 전처리팀**
    - 최대한 빨리 **"데이터 표준 스키마(최종 컬럼, 타입, null정책)" 문서/표**를
        
        **팀 전체에 공유**
        
    - 예:
        - tmdb 데이터: 영화_id, 제목, 개봉연도, 장르, 감독, 배우, ...
        - imdb 데이터: 영화_id, 평점, 투표수, ...
    - 이 표대로 **DB Table/Feast 피처/모델 코드 등 모두 설계**
2. **자동화팀**
    - DAG/컨테이너 구조/CI 코드/DB 적재 파이프라인 등
        
        **임시 컬럼/Raw 데이터 기반으로 우선 개발**
        
    - **최종 데이터 확정**되면
        
        단순히 컬럼명/타입만 일괄 교체(구조 유지)
        
3. **모델링팀**
    - Raw 데이터 기준으로 베이스라인 학습/MLflow 연동/모델 export 구조
        
        **최종 데이터 나오면 코드 일부 교체/재학습만 하면 됨**
        

---

### **4️⃣ 실무적 팁**

- **데이터 전처리팀**이
    
    **매일마다 "스키마(컬럼, 타입) 확정본" 갱신해서 공유**
    
    → 모든 팀원이 임시로 작업해도 **컬럼 구조만 맞추면 바로 통합/호환**
    
- **자동화·모델링팀**은
    
    **임시 컬럼/데이터**로 구조/자동화/학습·서빙 코드 미리 구축
    
    → **최종 데이터"만 받으면 바로 완성형 시스템에 대입**
    

---

### **⚡ 결론**

- **동시작업**이 실전/팀프로젝트에서 가장 효율적
- **임시 Raw 데이터/컬럼**으로 구조/코드/파이프라인 미리 완성
- **데이터 전처리팀이 확정본 공유 → 최종 데이터로 전환**
- **최종 컬럼/피처 반영은 '코드 일부 교체'만 하면 됨**
- **초기 데이터 스키마/컬럼만 '문서화'해서 팀 전체에 주기적 공유**가 핵심

---

## **🎯 최종 목표**

- **실전 MLOps 파이프라인 엔지니어링 경험 내재화**
- **실무·대회 수준의 배포/운영/자동화 역량 강화**
- 팀 내 적극적 협업과 DevOps 마인드 정착

---

# ⚙️ **프로젝트 운영 규칙**

본 프로젝트는 체계적 협업과 효율적 일정 관리를 위하여

아래와 같이 **프로젝트 운영/협업/관리 규칙**을 설정합니다.

이 규칙은 모든 팀원이 반드시 준수해야 하며,

세부 규칙/양식(이슈 관리, 커밋 규칙, 코드 리뷰 등)은 본 섹션 하위에 지속적으로 추가·보완합니다.

---

## 🏷️ **GitHub 이슈 라벨 체계 및 적용 가이드**

MLOps 프로젝트에서 모든 이슈/PR을 명확히 관리하기 위해

아래와 같이 **공식 라벨 목록**과 **운영 원칙**을 정의합니다.

### 🏷️ **라벨 목록 및 용도**

| 라벨명 | 설명 |
| --- | --- |
| analysis | 데이터 분석 (EDA, 결측치 통계, 분포 분석 등) |
| automated-pipeline | Airflow 등 자동화 파이프라인 관련 |
| bug | 버그 이슈 추적용 |
| CI/CD | GitHub Actions, 배포 자동화 관련 |
| controltower | 서버2: 오케스트레이션/서빙 서버 관련 |
| data-engineering | 데이터 수집/정제/전처리 작업 |
| database | PostgreSQL 등 DB 구성/이슈 |
| documentation | 문서 추가/보완 (PRD, README 등) |
| duplicate | 중복 이슈 표시용 |
| enhancement | 기능 개선 요청 또는 성능 개선 |
| feature-engineering | 피처 생성/가공 관련 작업 |
| help wanted | 팀원 도움 또는 논의 필요 항목 |
| infra | EC2, 네트워크, 보안 등 인프라 구축 |
| installation | 패키지, 툴 설치 관련 |
| invalid | 잘못된 이슈 또는 무효 처리 |
| mlops-pipeline | 전체 MLOps 흐름/워크플로우 관련 |
| modeling | 모델링, 학습, 튜닝, 성능 평가 |
| monitoring | Prometheus, Grafana, ELK 관련 작업 |
| nervous | 서버3: 모니터링/트리거 서버 관련 |
| planning | PRD, 기획서 등 계획 수립 단계 |
| question | 추가 설명 또는 질의 응답용 |
| server-setup | EC2 초기 세팅, 보안 설정 등 |
| serving | 모델 서빙(FastAPI, 엔드포인트) 관련 |
| submission | 대회 제출 결과물 관리용 |
| trigger | Alertmanager, 재학습 등 트리거 구성 |
| urgent | 긴급 우선 처리 필요 항목 |
| wontfix | 해결하지 않을 이슈 (보류/폐기) |
| workhorse | 서버1: 데이터/모델링 서버 관련 |
| mlflow | 실험 관리, 모델 레지스트리 관련 이슈 |
| airflow | DAG 구성, 스케줄링, 에러 관리 관련 |
| feast | 피처 스토어(Feast) 관련 구성/이슈 |
| fastapi | 모델 서빙 API 구현, 라우터 구성 등 |
| s3 | 모델/데이터/아티팩트 저장소 관련 |
| security | SSH, SSM, Secrets, IAM 권한 등 보안 관련 |
| jupyter | JupyterLab 환경 구축 및 분석 환경 이슈 |
| docker | Dockerfile, 이미지 관리, 컨테이너 관련 |
| redis | Redis 관련 설정/운영, Feast 온라인 피처 연동 |
| kafka | Kafka 기반 실시간 로그/이벤트 스트리밍, 토픽 관리, 데이터 파이프라인, 메시지 큐 등 관련 작업에 사용 |
| elk-stack | Elastic Stack(Elasticsearch, Logstash, Kibana) 기반 로그/이벤트 수집, 검색, 대시보드 구축, 운영 이슈에 사용 |
| nginx | Nginx 웹 서버 및 리버스 프록시 설정, API Gateway/서빙 인프라 관련 작업에 사용 |

---

### 📋 **라벨 운영 원칙 요약**

- 모든 이슈/PR 생성 시 **라벨 최소 1개 이상 부착** 필수
- 역할/구성요소 기반 라벨(예: `workhorse`, `controltower`, `nervous`, `airflow`, `mlflow` 등) 병행 사용 권장
- 기존 라벨로 구분 불가한 경우, 신규 라벨 제안 및 본 이슈에 코멘트로 기록
- 이슈 상태(duplicate, invalid, urgent 등)는 라벨로 별도 명시
- **이슈 생성 시, 반드시 프로젝트/보드와 연결하여 전체 일정·업무 흐름을 관리**해야 함

---

> 정리
> 
> 
> 팀원들은 **이슈 등록 → 라벨 및 타입 지정 → 프로젝트/보드 연동**을 반드시 지키며,
> 
> 진행 중 추가 이슈는 서브이슈로 분리 관리합니다.
> 
> 이는 투명한 협업, 효율적 일정 관리, 책임 분배, 최종 산출물 이력 추적의 핵심 기준입니다.
> 

---

# 🖥️ **인프라 및 서버 환경 구축 가이드**

본 프로젝트의 실질적 운영을 위해 AWS EC2 서버 3대를 활용하며,

서버별 주요 역할과 모든 환경 구축 및 소프트웨어 설치 기준, 체크리스트를 명확히 규정합니다.

이 가이드는 실제 배포·운영·테스트 시 실질적 기준이 됩니다.

---

## **🌐 EC2 서버 3대 초기 구성 및 환경 준비 작업**

### 📌 **목적**

- `mlops-controltower`, `mlops-nervous`, `mlops-workhorse` 서버를 PRD 문서 기준으로 각 역할에 맞게 생성,
    
    공통 및 전용 패키지/환경을 구성하는 초기 세팅 작업입니다.
    

### ✅ **작업 목표**

- EC2 서버 3대 생성 완료
- 서버 공통 패키지 설치 (`apt`, `docker`, `python`, `tmux`, `vim` 등)
- 서버별 역할별 필수 도구 설치
- Docker 동작 확인, 그룹 권한 설정, SSH 키 접근 및 보안 등

### 🛠️ **서버 공통 설치 패키지**

- `curl`, `wget`, `git`, `zip`, `unzip`, `htop`, `vim`, `tmux`
- `python3`, `python3-pip`, `docker.io`, `docker-compose`
- `ca-certificates`, `software-properties-common`, `build-essential`, `net-tools`, `tree`

### 설치 명령어 예시

```bash
sudo apt update && sudo apt upgrade -y
sudo apt install -y curl wget git zip unzip htop vim tmux \
  python3 python3-pip docker.io docker-compose \
  ca-certificates software-properties-common build-essential net-tools tree
sudo usermod -aG docker $USER
```

---

## **🚦 공통 서버 환경 준비 및 기본 설치**

### 📌 목적

- 각 서버별 고유 환경 구축 전,
    
    네트워크, 계정, 패키지, 보안 등 **모든 서버에서 반드시 먼저 진행해야 하는**
    
    공통/선행 작업 가이드입니다.
    

### ✅ 체크리스트

- EC2 인스턴스 보안 그룹/네트워크/방화벽 설정
- 공통 계정 및 권한 관리, SSH 키 배포/접근권한
- OS 및 주요 패키지 설치 (위 명령어 참고)
- Docker/Docker Compose 설치 및 정상작동 확인
- SSH 보안 강화(루트 접속 차단, 키 인증만 허용 등)
- 타임존, 로케일, 호스트명, 폴더 구조 표준화
- (선택) Fail2ban, UFW 등 1차 침입 방지/방화벽 적용

---

## **1️⃣ mlops-workhorse (데이터 & 모델링 서버) 환경 구축**

### 📌 목적

- **TMDB/IMDB 데이터 수집~~적재~~피처~~실험~~모델 관리** 등
    
    데이터/모델 파이프라인의 중심 서버 환경 구축
    

### ✅ 체크리스트

1. **데이터 파이프라인 및 적재**
    - TMDB/IMDB API 크롤러 개발, 스케줄러(예: Airflow), 표준 스키마/결과 공유
    - PostgreSQL, S3 적재 자동화, Airflow DAG 연동
2. **피처 엔지니어링/Feature Store(Feast) 구축**
    - Feast Core/Redis/S3 연동, 피처뷰/엔티티 설계
3. **모델 학습/실험 환경**
    - JupyterLab, MLflow Tracking Server, 실험/모델/아티팩트 관리
4. **컨테이너 오케스트레이션**
    - Docker Compose로 주요 서비스(MLflow, Feast, Airflow, PostgreSQL, Redis, JupyterLab 등) 상시 운영
5. **모니터링 연동**
    - health check endpoint, 로그/이벤트/지표를 nervous 서버로 연동
6. **설치/설정/로그 기록**
    - `server-setup-log.md`, Notion 등 기록

### 설치 예시

```bash
sudo apt install -y postgresql postgresql-contrib redis-server awscli
pip install requests mlflow "feast[redis,s3]" apache-airflow jupyterlab
docker-compose up -d
```

---

## **2️⃣ mlops-controltower (오케스트레이션/서빙 서버) 환경 구축**

### 📌 목적

- **Airflow, FastAPI, Nginx, CI/CD, 보안, 인증 등
전체 오케스트레이션/서빙/배포/DevOps 환경 구축**

### ✅ 체크리스트

1. **Airflow Webserver/Scheduler 배포, 계정/비번/포트 보안, 로그/실행이력 관리**
2. **FastAPI & Uvicorn 앱 컨테이너 배포, Nginx 리버스 프록시(SSL/로그 관리)**
3. **CI/CD 자동화(GitHub Actions, AWS CLI, Docker Compose, 배포 자동화/롤백 등)**
4. **보안(인증/접근제어/로그/도메인/SSL 등), 서비스별 health check**
5. **설치/운영/로그 기록**

### 설치 예시

```bash
sudo apt install -y nginx awscli
pip install apache-airflow fastapi uvicorn
```

---

## **3️⃣ mlops-nervous (모니터링/트리거 서버) 환경 구축**

### 📌 목적

- **Kafka, Zookeeper, ELK Stack, Prometheus, Grafana, Alertmanager 등
실시간 로그/지표/이벤트/알림의 중앙 허브 환경 구축**

### ✅ 체크리스트

1. **Kafka, Zookeeper, Logstash, Elasticsearch, Kibana 컨테이너 배포/연동**
2. **Prometheus, Grafana, Alertmanager 배포 및 연동(모든 서버 지표/알람/트리거 자동화)**
3. **컨테이너 관리/보안/네트워크 표준화, health check, IAM, S3 연동 등**
4. **E2E 테스트, Alert 샘플/테스트, 모든 설치/설정/운영 이력 기록**

### 설치 예시

```bash
docker-compose up -d
sudo apt install -y awscli
```

---

### 📂 **공통 로그 기록 지침**

- 모든 설치/설정/운영 명령어 및 결과 로그는 `server-setup-log.md` 또는 Notion에 기록
- Docker 실행 실패 시, 상세 로그 포함하여 이슈 코멘트로 공유

---

## 🗓️ EC2 서버 표준 환경 설정 (타임존, 로케일, 호스트명)

### 📌 목적

- MLOps 서버 전체의 운영 표준화 및 실무 관리 편의성을 확보하기 위해,
    
    OS 레벨에서 타임존, 로케일, 호스트명을 통일함.
    
- 이는 협업 시 로그 분석, 장애 추적, 시스템 명명 규칙 일관성을 유지하는 데 필수적이며,
    
    이후 보안 설정(UFW, SSH, Fail2ban 등)의 기반이 되는 핵심 선행 작업임.
    

---

### 🛠️ 타임존 및 로케일 설정

- 서버의 시스템 시간대는 `Asia/Seoul(KST)` 기준으로 설정
- 로케일은 한글 UTF-8 환경(`ko_KR.UTF-8`)으로 통일

```bash
# 타임존 설정
sudo timedatectl set-timezone Asia/Seoul

# 로케일 설정
sudo locale-gen ko_KR.UTF-8
sudo update-locale LANG=ko_KR.UTF-8
source /etc/default/locale
```

---

### 🖥️ 호스트명 설정 (서버별 역할 기반 명명)

- 서버별 고유 역할에 따라 일관된 호스트명을 설정함

```bash
# 서버 1 – 데이터/모델링 서버
sudo hostnamectl set-hostname chh-mlops-workhorse
```

```bash
# 서버 2 – 오케스트레이션/서빙 서버
sudo hostnamectl set-hostname chh-mlops-controltower
```

```bash
# 서버 3 – 모니터링/트리거 서버
sudo hostnamectl set-hostname chh-mlops-nervous
```

---

### ℹ️ 운영 상 유의사항

- 위 설정은 폴더 구조, 로그 파일 경로, 모니터링 및 경보 시스템 설정 시
    
    서버 식별을 명확히 하고, 협업 및 장애 대응 시 중복/혼선을 방지함
    
- 모든 서버는 설정 적용 후 다음 명령어로 검증 가능함:

```bash
hostname
timedatectl
locale
```

---

## 🔐 AWS EC2 인스턴스 보안 그룹/네트워크/방화벽 인바운드 규칙 최적화

### 📌 목적

- MLOps 시스템의 보안성과 운영 효율을 높이기 위해, 각 서버별 보안그룹을 분리 구성함.
- 서비스별 실제 사용 포트 및 프로토콜을 기준으로, **최소 권한 원칙(Principle of Least Privilege)**에 따라 인바운드 규칙을 세부적으로 설정함.
- 불필요한 외부 노출(`0.0.0.0/0`)은 차단하고, 내부 통신은 VPC CIDR 또는 보안그룹 ID 기준으로 제한적으로 허용함.
- 보안 그룹 변경 및 테스트 내역은 별도 운영 기록 파일(server-setup-log.md, Notion)에 문서화함.

---

### 🌐 서버별 인바운드 규칙 구성

1. mlops-workhorse (데이터/모델링 서버)
    - SSH(22/tcp)는 팀원 및 관리자 고정 IP에 한정하여 허용함.
    - PostgreSQL(5432/tcp), Redis(6379/tcp)는 동일 VPC 또는 내부 보안그룹 ID를 통한 접근만 허용하며 외부 전면 차단.
    - JupyterLab 및 Feast(8888/tcp), MLflow Tracking(5000/tcp)는 운영 중 임시 외부 테스트용으로만 팀원 IP 허용 가능하며, 테스트 종료 후 즉시 차단.
    - AWS CLI와 같은 외부 API 접근은 443 포트를 통한 **아웃바운드 통신**만 허용하며, 인바운드는 전면 차단.

2. mlops-controltower (오케스트레이션/서빙 서버)

- SSH(22/tcp), Airflow Webserver(8080/tcp), FastAPI(8000/8081/tcp)는 팀원 및 관리자 IP만 허용.
- FastAPI 서빙은 실 서비스 운영 시에만 임시 오픈하며, 테스트 종료 후 즉시 비활성화.
- Nginx HTTP/HTTPS(80,443/tcp)는 도메인 및 외부 서비스 운영 시에만 한정적으로 허용.
- Docker/Airflow CLI용 포트(2375/tcp)는 내부 오케스트레이션 목적에 한정하여 VPC 또는 보안그룹 내부 통신만 허용.
- PostgreSQL 연동 포트(5432/tcp)는 Workhorse 보안그룹에서만 접근 가능하도록 설정.

3. mlops-nervous (모니터링/트리거 서버)

- SSH, Grafana(3000), Kibana(5601), Prometheus(9090), Alertmanager(9093)는 팀원 및 관리자 IP에만 한정하여 접근 허용.
- Kafka(9092), Zookeeper(2181), Elasticsearch(9200), Logstash(5044)는 **동일 VPC 또는 내부 보안그룹 ID**에서만 접근 가능하며 외부 전면 차단.
- AWS 관련 서비스 접근은 443 포트를 통한 아웃바운드만 허용하며, 인바운드는 차단함.

---

### 📊 인바운드 포트 규칙 요약표

| 서버 | 서비스 | 포트 | 외부 허용 | 설명 |
| --- | --- | --- | --- | --- |
| Workhorse | SSH | 22/tcp | 팀원 IP | 외부 접속 제한 |
| Workhorse | PostgreSQL | 5432/tcp | 내부만 | DB 간 통신 전용 |
| Workhorse | JupyterLab/Feast | 8888/tcp | 내부/필요시만 | 실습 시 임시 허용 |
| Workhorse | MLflow Tracking | 5000/tcp | 내부/필요시만 | 실험 관리 UI |
| Workhorse | Redis | 6379/tcp | 내부만 | 피처스토어 연동 |
| Controltower | SSH | 22/tcp | 팀원 IP | 외부 접속 제한 |
| Controltower | Airflow Webserver | 8080/tcp | 팀원 IP | DAG 관리 UI |
| Controltower | FastAPI(Uvicorn) | 8000,8081/tcp | 필요시만 | 예측 API 서빙 |
| Controltower | Nginx/HTTP(S) | 80,443/tcp | 필요시만 | 실 서비스 시 오픈 |
| Controltower | Docker/Airflow CLI | 2375/tcp | 내부만 | 내부 오케스트레이션 |
| Controltower | PostgreSQL 연동 | 5432/tcp | 내부만 | DB 연동 전용 |
| Nervous | SSH | 22/tcp | 팀원 IP | 외부 접속 제한 |
| Nervous | Grafana | 3000/tcp | 팀원 IP | 대시보드 접근 제한 |
| Nervous | Kibana | 5601/tcp | 팀원 IP | 로그 시각화 UI |
| Nervous | Prometheus | 9090/tcp | 팀원 IP | 지표 수집 확인용 |
| Nervous | Alertmanager | 9093/tcp | 팀원 IP | 경보 트리거 처리 |
| Nervous | Kafka/Broker | 9092/tcp | 내부만 | 실시간 이벤트 |
| Nervous | Zookeeper | 2181/tcp | 내부만 | Kafka 연동 |
| Nervous | Elasticsearch | 9200/tcp | 내부만 | 로그 검색 백엔드 |
| Nervous | Logstash | 5044/tcp | 내부만 | 로그 수집 처리 |

---

### 🔧 AWS 보안그룹 적용 및 운영 가이드

- 각 서버는 AWS 콘솔 내 **보안 그룹에서 역할명 기준으로 명확히 생성 및 구분**함.
- 인바운드 규칙은 각 포트/프로토콜/허용대역을 명시된 표에 따라 입력하며,
    
    IP 허용 범위는 **고정 공인 IP** 또는 **VPC CIDR** / **보안그룹 ID** 방식으로 구성함.
    
- 불필요한 포트(`0.0.0.0/0`)는 반드시 차단하며, 테스트 목적 임시 오픈 후 즉시 닫는 것을 원칙으로 함.
- 모든 인바운드 변경 사항은 운영 이력 문서에 기록하고, 주기적으로 보안 점검을 수행함.

---

## 🛡️ Ubuntu 서버 OS 방화벽(UFW) 및 침입 탐지(Fail2ban) 구성

### 📌 목적

- MLOps 서버 운영 시, **OS 레벨에서의 보안 강화**를 위해 `UFW`(Uncomplicated Firewall)를 활용한 **기본 방화벽 정책 설정**,
    
    그리고 `Fail2ban`을 통한 **SSH Brute-force 공격 탐지 및 차단** 체계를 구축함.
    
- AWS 보안그룹 인바운드 설정과 UFW 설정을 **이중 방어 체계로 구성**하여 실수, 침입, 취약점에 대비하고,
    
    실제 운영 시에도 **내부 트래픽만 허용**하는 보안 원칙을 유지함.
    

---

### 🔐 서버별 방화벽 구성 개요

- **UFW는 모든 서버에서 기본적으로 비허용 정책 적용 후, 각 서버의 인바운드 포트만 명시적으로 허용**
- 팀원 고정 IP는 `<YOUR_TEAM_IP>` 자리에 입력
- 내부 서비스 통신은 AWS VPC 대역인 `172.31.0.0/16`을 기준으로 설정

---

### 1️⃣ chh-mlops-workhorse (데이터/모델링 서버)

- SSH(22)는 고정 IP만 허용
- PostgreSQL(5432), Redis(6379)는 내부 VPC 통신만 허용
- JupyterLab(8888), MLflow Tracking(5000)은 실습 시 임시로만 외부 허용 가능

```bash
sudo apt install -y ufw fail2ban
sudo ufw default deny incoming
sudo ufw default allow outgoing

# SSH
sudo ufw allow 22/tcp

# 내부 서비스 연동
sudo ufw allow from 172.31.0.0/16 to any port 5432 proto tcp    # PostgreSQL
sudo ufw allow from 172.31.0.0/16 to any port 6379 proto tcp    # Redis

# 실습용 외부 허용 (임시)
sudo ufw allow from <YOUR_TEAM_IP> to any port 8888 proto tcp   # JupyterLab
sudo ufw allow from <YOUR_TEAM_IP> to any port 5000 proto tcp   # MLflow Tracking

sudo ufw enable
sudo ufw status
sudo systemctl enable --now fail2ban
sudo systemctl status fail2ban
```

---

### 2️⃣ chh-mlops-controltower (오케스트레이션/서빙 서버)

- SSH(22), Airflow UI(8080), FastAPI(8000/8081), Nginx(80/443)는 고정 IP에서만 허용
- Docker/Airflow CLI(2375), PostgreSQL(5432)는 내부 VPC 대역에서만 허용

```bash
sudo apt install -y ufw fail2ban
sudo ufw default deny incoming
sudo ufw default allow outgoing

# SSH
sudo ufw allow 22/tcp

# 외부 접속 포트 (임시 허용)
sudo ufw allow from <YOUR_TEAM_IP> to any port 8080 proto tcp   # Airflow Webserver
sudo ufw allow from <YOUR_TEAM_IP> to any port 8000 proto tcp   # FastAPI
sudo ufw allow from <YOUR_TEAM_IP> to any port 8081 proto tcp   # FastAPI Sub
sudo ufw allow from <YOUR_TEAM_IP> to any port 80 proto tcp     # Nginx HTTP
sudo ufw allow from <YOUR_TEAM_IP> to any port 443 proto tcp    # Nginx HTTPS

# 내부 연동
sudo ufw allow from 172.31.0.0/16 to any port 2375 proto tcp     # Docker/Airflow CLI
sudo ufw allow from 172.31.0.0/16 to any port 5432 proto tcp     # PostgreSQL

sudo ufw enable
sudo ufw status
sudo systemctl enable --now fail2ban
sudo systemctl status fail2ban
```

---

### 3️⃣ chh-mlops-nervous (모니터링/트리거 서버)

- SSH, Grafana(3000), Kibana(5601), Prometheus(9090), Alertmanager(9093)는 고정 IP에서만 허용
- Kafka(9092), Zookeeper(2181), Elasticsearch(9200), Logstash(5044)는 내부 VPC에서만 허용

```bash
sudo apt install -y ufw fail2ban
sudo ufw default deny incoming
sudo ufw default allow outgoing

# SSH
sudo ufw allow 22/tcp

# 외부 접속 포트 (운영자 UI)
sudo ufw allow from <YOUR_TEAM_IP> to any port 3000 proto tcp    # Grafana
sudo ufw allow from <YOUR_TEAM_IP> to any port 5601 proto tcp    # Kibana
sudo ufw allow from <YOUR_TEAM_IP> to any port 9090 proto tcp    # Prometheus
sudo ufw allow from <YOUR_TEAM_IP> to any port 9093 proto tcp    # Alertmanager

# 내부 연동 포트
sudo ufw allow from 172.31.0.0/16 to any port 9092 proto tcp     # Kafka
sudo ufw allow from 172.31.0.0/16 to any port 2181 proto tcp     # Zookeeper
sudo ufw allow from 172.31.0.0/16 to any port 9200 proto tcp     # Elasticsearch
sudo ufw allow from 172.31.0.0/16 to any port 5044 proto tcp     # Logstash

sudo ufw enable
sudo ufw status
sudo systemctl enable --now fail2ban
sudo systemctl status fail2ban
```

---

### ⚙️ 운영 팁 및 참고 사항

- `<YOUR_TEAM_IP>`에는 실습 운영자 고정 공인 IP를 입력 (예: `93.152.212.50`)
- `<VPC_CIDR>`은 AWS VPC 대시보드에서 확인 가능 (`172.31.0.0/16` 등)
- 실습 목적 외부 포트는 테스트 후 즉시 닫을 것 (`sudo ufw delete allow ...`)
- **AWS 보안그룹 인바운드와 UFW 허용 포트가 일치하지 않으면 통신 차단됨** – 반드시 양쪽 모두 설정해야 함
- 설정 이력은 `server-setup-log.md` 또는 Notion에 기록

---

## 🔐 SSH 보안 강화 (비밀번호 차단 + 키 인증만 허용)

### 📌 목적

MLOps 서버 전체의 보안, 운영 표준화, 실무 관리 편의성을 높이기 위한 서버별 SSH 강화 및 팀 협업/장애 추적에 필수적인 핵심 선행 작업을 세분화하여 명확하게 수행.

각 서버 공동 작업 사항으로 모든 서버에서 SSH 보안 강화 과정 실행.

---

### 🔐 SSH 보안 강화

```bash
# sshd_config 백업
sudo cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak
sudo vim /etc/ssh/sshd_config

# 아래 내용이 존재하도록 수정/추가
PermitRootLogin no
PasswordAuthentication no

# 적용
sudo systemctl daemon-reload
sudo systemctl restart ssh
```

---

### 🔑 SSH 키 발급부터 공개키 등록까지 전체 과정

1. 로컬 PC에서 SSH 키 쌍 생성

- SSH Key 생성 명령어:

```bash
ssh-keygen -t rsa -b 4096 -C "your_email@example.com"
```

- 입력 시 파일 경로 및 패스프레이즈(암호)는 기본값 엔터만 쳐도 무방.
- 생성 결과:
    - 개인키(`id_rsa`)
    - 공개키(`id_rsa.pub`)
- 생성한 SSH 키 파일 권한 설정 (cmd)

```bash
icacls your_id_rsa /inheritance:r
icacls your_id_rsa /grant:r %username%:R
icacls your_id_rsa /inheritance:r
```

---

2. EC2 서버에 공개키 등록

- **.pem 파일 권한 설정 (cmd)**

```bash
icacls.exe your_aws_key.pem /reset
icacls.exe your_aws_key.pem /grant:r %username%:(R)
icacls.exe your_aws_key.pem /inheritance:r
```

- **AWS에서 받은 .pem 파일로 서버 접속**

```bash
ssh -i your_aws_key.pem ubuntu@서버IP
```

- **로컬에서 생성한 공개키를 서버로 복사**
    - Windows 기준 MobaXTerm 드래그앤 드롭 형식으로 ‘id_rsa.pub’ 파일(SSH Key파일)을
        
        EC2 우분투 서버의 `.ssh/'폴더 안에 복사하기
        
        - **공개키 파일을 authorized_keys에 등록**
            
            EC2 서버에서 다음 명령어를 실행
            
            ```bash
            cat .ssh/your_id_rsa.pub >> .ssh/authorized_keys
            ```
            
            이렇게 하면 두 개의 공개키 모두 `authorized_keys` 파일에 추가
            
            (*다른 팀원의 공개키가 추가로 있다면, 똑같이 붙여넣기*)
            
    - Linux, macOS 또는 WSL(Windows Subsystem for Linux), Git Bash 등에서만 사용
        
        ```bash
        ssh-copy-id -i ~/.ssh/your_id_rsa.pub ubuntu@서버IP
        ```
        
        - `ssh-copy-id`가 없다면 위에 Windows 방법 처럼 SSH 파일 수동으로 서버로 복사 가능
- **authorized_keys 파일 권한 조정(필수)**

```bash
chmod 600 .ssh/authorized_keys
```

---

3. 로컬에서 개인키로 SSH 접속 테스트

- 접속 명령어:

```bash
ssh -i ~/.ssh/id_rsa ubuntu@서버IP
```

---

### 💾 sshd_config 백업 및 이력 관리

1. 변경 전후 파일 백업

- 목적: 설정 변경 시 문제 발생 대비 이전 설정으로 복구 가능하도록 백업.
    - `YYYYMMDD`: ‘YYYYMMDD’ 문구 그대로 입력하는게 아니라 등록 날짜를 직업 입력
        
        예) /etc/ssh/sshd_config.bak-20250729
        

```bash
sudo cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak-YYYYMMDD
```

---

2. 변경 이력 관리

- 목적: 변경자, 날짜, 사유를 기록하여 문제 발생 시 추적 가능.
- 기록 방법: `server-setup-log.md` 또는 Notion에 변경사항 기록.

---

3. 문제 발생 시 복구

- `YYYYMMDD`: ‘YYYYMMDD’ 문구 그대로 입력하는게 아니라 등록 날짜를 직업 입력
    
    예) /etc/ssh/sshd_config.bak-20250729
    

```bash
sudo cp /etc/ssh/sshd_config.bak-YYYYMMDD /etc/ssh/sshd_config
sudo systemctl restart ssh
```

---

### ℹ️ 추가 정보

### `/etc/ssh/sshd_config`와 `~/.ssh/authorized_keys` 관계성

- `/etc/ssh/sshd_config`: SSH 인증 방식 및 정책 설정
- `~/.ssh/authorized_keys`: 실제 접속 허용할 개인키 목록
- 둘 다 관리해야 완전한 SSH 보안 정책 적용 가능.

---

# 🔍 MLOps 파이프라인 핵심 도구 구성 및 기술적 선정 이유

## 📌 목적

- 본 프로젝트에서 사용하는 모든 주요 기술 도구(스토리지, 플랫폼, 프레임워크, 패키지 등)의 **선정 목적, 사용 위치, 기능, 대안 비교, 실무 적용 방식**을 명확히 기술함.
- 특히 MLOps를 처음 접하는 팀원들이 도구 간 구분 및 목적을 혼동하지 않도록, **Feast 기반 Feature Store, Online/Offline Store 개념, 실시간 서빙과 배치 학습의 차이**를 중심으로 설명함.
- 또한 PostgreSQL만으로는 피처 관리가 불가능한 이유, S3와 함께 사용하는 이유, Redis를 사용하는 이유 등을 모두 구체화함.

## 1️⃣ PostgreSQL

- **역할**:
    
    정형 데이터 저장소 / 메타데이터 관리 / 피처 테이블 저장 / 실험 이력 기록 DB
    
- **사용처**:
    - TMDB, IMDB 등 외부 데이터 → 전처리 → `movies`, `ratings`, `feature_movies` 등의 테이블 저장
    - Feast에서 피처 뷰 정의, 엔티티 등록 등 **모든 메타데이터 기록 저장소**
    - MLflow 실험 정보(하이퍼파라미터, 성능 지표, 모델 버전) 기록
    - Airflow DAG 실행 이력, 태스크 상태 기록
- **선정 이유**:
    1. **기술적 신뢰성 및 호환성**
        - ANSI SQL 표준 준수율이 높고, JSONB, 배열, 확장 타입 등 유연한 데이터 모델링 가능
        - 다양한 확장 모듈(PostGIS, TimescaleDB 등)을 통한 시공간, 시계열 데이터 처리까지 확장 가능
        - **MLflow, Airflow, Feast와의 공식 연동 백엔드로 지정된 유일한 RDBMS** 중 하나
    2. **운영 편의성 및 컨테이너 호환**
        - OSS(Open Source Software) 기반으로 **라이선스 제약이 전혀 없고**, 클라우드/로컬 모두 동일한 방식으로 운용 가능
        - Docker 이미지 공식 제공 및 Kubernetes, Airflow 연동 등 DevOps/MLOps 환경에서 사용 용이
        - PostgreSQL은 메모리 사용량 조절 및 확장성 튜닝이 가능하여 작은 실습 환경~대형 서비스까지 일관 운영 가능
    3. **MLOps 실무 관점에서의 표준**
        - ML 실험을 반복하는 환경에서는 **이력 추적, 피처 정의, 실험 메타데이터 기록이 핵심**
        - PostgreSQL은 SQL 기반으로 피처 테이블을 직접 조회하고, EDA 및 파이프라인 연동도 간결함
        - S3나 Redis와 달리, **정형 데이터의 저장/조회/정합성 검증**에 최적화되어 있음
    4. **교육 및 협업 측면**
        - 초급자부터 고급자까지 **가장 학습이 용이한 RDBMS**, SQL 기반 수업과도 연계
        - 실습 시 로컬 환경에서도 가볍게 실행 가능하고, 팀원 간 DB 공유에도 용이함

### 🧪 도구 선정 비교:

| 항목 | PostgreSQL | MySQL | MariaDB | Oracle | MSSQL | ClickHouse | SQLite | Google BigQuery |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| OSS 여부 | ✅ 완전 오픈 | ✅ (제한) | ✅ | ❌ 유료 | ❌ 유료 | ✅ 분석 특화 | ✅ 로컬용 | ❌ 유료 |
| SQL 표준 호환 | ✅ 우수 | ⛔ 일부 제한 | ✅ | ⛔ 독자 확장 | ⛔ T-SQL 기반 | ✅ (제한적) | ✅ (기본형) | ✅ (비용 있음) |
| MLOps 연동성 | ✅ 공식 지원 | ⛔ 미지원 | ⛔ 미지원 | ⛔ 복잡 | ⛔ 제약 많음 | ⛔ 없음 | ⛔ 미지원 | ⛔ Feast/MLflow 비공식 |
| 확장성 | ✅ 풍부 | ⛔ 한계 있음 | ⛔ 수평 한계 | ✅ 상용 기능 | ⛔ Windows 종속 | ✅ 수직 우수 | ⛔ 단일 파일 | ✅ (대규모 분석) |
| 컨테이너 배포 용이성 | ✅ 공식 이미지 | ✅ 있음 | ✅ 있음 | ⛔ 무거움 | ⛔ 환경 제약 | ✅ | ✅ | ⛔ 미지원 |
| 피처 저장 및 조회 | ✅ 강력 | ⛔ JOIN/인덱스 제한 | ⛔ 일부 제약 | ✅ (고비용) | ⛔ (속도 저하) | ✅ 분석 최적화 | ⛔ 제한적 | ✅ (분석 최적화) |

### 📝 최종 평가 및 선택 사유 요약

> PostgreSQL은 본 프로젝트에서 정형 데이터 저장, 메타데이터 관리, Feast/MLflow/Airflow 공식 연동성,
> 
> 
> **팀 협업/실습 환경 최적화**를 동시에 충족할 수 있는 **가장 안정적이고 실무 친화적인 데이터베이스**입니다.
> 
> 다양한 후보군(MariaDB, Oracle, MSSQL, SQLite 등) 중에서도,
> 
> **학습 난이도, 운영 자유도, MLOps 호환성, 오픈소스 안정성**을 기준으로 **PostgreSQL이 가장 높은 점수를 충족**하여 최종 선택되었습니다.
> 

---

## 2️⃣ S3 (Amazon Simple Storage Service)

- **역할**:
    
    비정형/대용량 데이터 저장소 / Offline Feature 저장 / 모델 아티팩트 저장 / 장기 백업 보관소
    
- **사용처**:
    - Feast의 **Offline Store**로 사용 → 학습용 피처 데이터를 `.parquet`, `.csv` 형식으로 저장
    - MLflow의 **Artifact Store**로 사용 → 모델 파일, 메트릭 시각화, 학습 결과 등 저장
    - Airflow 전처리 DAG에서 생성한 중간 결과물 저장
    - 원본 Raw 데이터, 외부 API 수집 결과의 장기 백업
- **선정 이유**:
    1. **무제한 확장성과 글로벌 안정성**
        - AWS 인프라 기반으로 수 PB 이상 확장 가능
        - 오브젝트 단위 저장방식으로 파일 수/크기 제한이 사실상 없음
        - 자동 이중화, 고가용성, 복제 기능으로 데이터 안전성 확보
    2. **MLOps 도구 연동 최적화**
        - Feast에서 Offline Feature Store로 **공식 지원**
        - MLflow에서 Artifact Store로 **기본 권장 저장소**
        - Python, boto3, s3fs 등 풍부한 라이브러리와 SDK 제공
    3. **비정형 데이터 및 대용량 처리에 적합**
        - `.parquet`, `.csv`, `.json`, `.zip`, `.pkl` 등 모든 파일 포맷 저장 가능
        - 메타데이터와는 별도로, **실제 학습·서빙에 쓰이는 피처, 모델, 로그** 저장소로 활용
    4. **운영 편의성과 비용 효율성**
        - 버킷/폴더 기반 구조로 관리 편리
        - IAM 권한 제어로 접근제어 세분화 가능
        - S3 표준 스토리지 외에도 Infrequent Access / Glacier 등 장기보관 옵션 지원 → 비용 절감
    5. **실무 기준 표준**
        - 대부분의 대형 AI/ML 시스템에서 **오프라인 피처 스토어 표준**으로 채택
        - MLOps 파이프라인 구성 시, 데이터 마트, 백업, 분석 결과 저장에도 다용도 활용 가능

### 🧪 도구 선정 비교:

| 항목 | S3 (AWS) | HDFS | MinIO | GCS (Google) | NAS | Ceph (Rook) | Azure Blob | FTP/SFTP |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 확장성 | ✅ 무제한 | ⛔ 클러스터 제한 | ⛔ 로컬 디스크 기반 | ✅ 무제한 | ⛔ 물리적 장비 한계 | ✅ 수평 확장 | ✅ 무제한 | ⛔ 용량/속도 제약 |
| MLOps 연동성 | ✅ Feast/MLflow 공식 | ✅ Spark 기반 가능 | ⛔ 수동 설정 필요 | ✅ Feast/MLflow 지원 | ⛔ 연동 어려움 | ⛔ 복잡한 구성 필요 | ✅ 일부 도구 지원 | ⛔ 미지원 |
| 운영 복잡도 | ✅ 쉬움 | ⛔ 클러스터 관리 복잡 | ✅ 중간 | ✅ 쉬움 | ⛔ 장비/네트워크 구성 필요 | ⛔ Helm 및 수동 구성 | ✅ 쉬움 | ⛔ 수동 업로드 |
| 비용 | ✅ 저렴 (요금제 다양) | ⛔ 장비 구입 필수 | ✅ 저비용 실습용 | ✅ 유사 요금제 | ⛔ 유지관리 비용 발생 | ✅ OSS 기반 | ✅ 유사 구조 | ⛔ 고정 인프라 필요 |
| 보안/이중화 | ✅ 자동화 | ⛔ 직접 설정 필요 | ⛔ 백업 수동 | ✅ GCP 보안 | ⛔ 수동 백업 필요 | ✅ 분산 저장 지원 | ✅ MS 보안 통합 | ⛔ SSH/전송만 암호화 |
| 파일 유형 지원 | ✅ 전 포맷 | ✅ 제한 없음 | ✅ 제한 없음 | ✅ 제한 없음 | ⛔ 일부 포맷 제약 | ✅ 전체 지원 | ✅ 전체 지원 | ⛔ 바이너리 등 제한 많음 |
| 실무 적용도 | ✅ 대부분 환경 | ✅ Spark 환경 전용 | ⛔ 개인 개발/테스트용 | ✅ 기업 실무 활용 | ⛔ 실무 적용 낮음 | ⛔ 대규모용 특화 | ✅ 클라우드 실무 활용 | ⛔ 실무 미적합 |

### 📝 최종 평가 및 선택 사유 요약

> S3는 정형/비정형 데이터를 모두 저장할 수 있고, 확장성과 보안, 비용 측면에서 모든 조건을 만족하며,
> 
> 
> **Feast 및 MLflow의 오프라인 저장소로 공식 지원**되어 MLOps 파이프라인의 Offline Feature Store로 최적입니다.
> 
> MinIO, HDFS, NAS, Ceph 등 다양한 대안이 있지만,
> 
> - HDFS: 초기 셋업 및 관리 복잡, Spark 외 연계도구 부족
> - MinIO: 로컬 기반 테스트용은 좋으나, 확장/이중화에 한계
> - NAS: 물리적 인프라 의존성 큼, 팀 프로젝트엔 부적합
> - Ceph: 설치/구성 난이도 높고 팀 협업/실습 환경에 과함
> 
> **클라우드 기반의 학습용/운영용 환경 모두에서 일관된 성능, 확장성, 연동성을 제공하는 S3가 가장 적합하므로 최종 채택**되었습니다.
> 

---

<aside>
💡

## PostgreSQL과 S3를 함께 사용하는 이유

### 📌 배경

MLOps 파이프라인에서는 단순히 데이터를 저장하는 것 이상의 작업이 요구됩니다.

**데이터의 종류, 목적, 사용 시점, 연산 방식**에 따라

서로 다른 저장소(PostgreSQL, S3)를 함께 구성해야

**효율적이며 안정적인 파이프라인**을 운영할 수 있습니다.

---

### 📘 정형 데이터 vs 📁 비정형 데이터

| 구분 | 정형 데이터 (Structured) | 비정형 데이터 (Unstructured) |
| --- | --- | --- |
| 형식 | 테이블(행/열) 구조 | 자유 형식 (파일, JSON, 이미지 등) |
| 예시 | 영화 ID, 제목, 평점, 장르 | 포스터 이미지, 리뷰 텍스트, 모델 파일 |
| 저장 방식 | RDBMS (예: PostgreSQL) | 오브젝트 스토리지 (예: S3) |
| 특징 | SQL로 쿼리/연산 가능 | 단순 저장/불러오기, 분석은 별도 필요 |

---

### 🧩 메타데이터란?

- 메타데이터는 "**데이터를 설명하는 데이터**"입니다.
- 예시:
    - 모델 실험 결과의 **하이퍼파라미터, 성능 지표, 실행 날짜**
    - 피처 뷰의 **정의 정보, 버전, 생성 시간**
    - DAG의 **실행 상태, 태스크 성공/실패 기록**

> 📌 메타데이터는 PostgreSQL 같이 구조화된 RDBMS에서 관리해야
> 
> 
> **SQL로 추적/관리/필터링**이 가능하고,
> 
> 실험 이력이나 피처 정의를 **재현성 있게 운영**할 수 있습니다.
> 

---

### ✅ 왜 PostgreSQL + S3를 함께 써야 하는가?

| 항목 | PostgreSQL 단독 사용 | S3 단독 사용 | PostgreSQL + S3 병행 사용 |
| --- | --- | --- | --- |
| 정형 데이터 저장 | ✅ 최적 | ⛔ 불편 (파일로 저장) | ✅ PostgreSQL에 저장 |
| 비정형/대용량 저장 | ⛔ 한계 | ✅ 최적 | ✅ S3에 저장 |
| 피처 엔지니어링 | ✅ SQL 활용 | ⛔ 직접 분석 어려움 | ✅ SQL + 파일 연동 |
| Feast 연동 | ✅ 메타데이터 기록용 | ✅ 오프라인 피처 저장용 | ✅ 메타+피처 분리 저장 |
| 실험 이력 관리 | ✅ MLflow Tracking 가능 | ⛔ 아티팩트 외 정보 저장 불가 | ✅ 실험 + 모델 저장 분리 |
| 데이터 버전 관리 | ✅ 쿼리로 추적 | ⛔ 수동 버전 관리 필요 | ✅ 이력 추적 + 파일 버전 |
| 비용 효율성 | ⛔ 저장 용량↑ | ✅ 장기 저장에 효율 | ✅ 분리 저장으로 최적화 |

---

### 📉 PostgreSQL만 사용할 경우의 문제점

- **비정형/대용량 데이터 저장 불가**
    - `.parquet`, `.pkl`, `.jpg` 등은 테이블에 저장 불가능하거나 비효율적
- **장기 백업, 파일 기반 분석 불편**
    - 파일 단위 백업, 외부 공유 등 어려움
- **모델 아티팩트 및 분석 결과 저장에 부적합**

### 📉 S3만 사용할 경우의 문제점

- **정형 데이터에 대한 쿼리 불가**
    - SQL로 직접 분석이 불가, 데이터 가공/조인/통계 불편
- **메타데이터 기록/이력 추적 불가**
    - 실험 일자, 피처 버전 등 추적 불가
- **Feast, MLflow 등 주요 OSS 연동시 제약**

---

### ✅ 두 시스템을 함께 사용할 때의 장점

> Feast 기준으로 설명
> 
- **PostgreSQL**: 피처 뷰/엔티티/소스 등록 시 모든 **정의 정보 저장소**
- **S3**: 실제 학습에 사용할 피처 데이터(`.parquet`)를 저장 → **Offline Store**
- **결과**: 메타 관리와 피처 데이터를 분리함으로써 **일관된 실험, 재현성, 확장성 확보**

---

### 📝 실무 비유

- **PostgreSQL = 설계도/노트**: 구조, 이력, 정의를 추적
- **S3 = 창고/작업물**: 실제 데이터를 저장
- **둘 다 있어야** "어떤 작업을 어떻게 했는지 + 실제 결과물"을 함께 보관할 수 있음

---

### 🚩 결론 요약

- **PostgreSQL**: 정형 데이터, 실험 이력, 메타 정보 추적에 필수
- **S3**: 비정형/대용량 데이터, 피처/모델 저장에 필수
- **MLOps에서는 두 저장소가 서로 보완되며 함께 사용될 때**
    
    전체 파이프라인의 **자동화, 추적성, 확장성**이 실현됩니다.
    

---

</aside>

---

## 2️⃣-1️⃣ Feast (Feature Store)

- **역할**:
    
    피처 정의 / 버전 관리 / 학습 및 서빙 환경 간 피처 일관성 보장 / 오프라인·온라인 피처 분리 저장소 자동화
    
- **사용처**:
    - 전처리된 피처 테이블을 기반으로 **Feature View 및 Entity 등록**
    - Feast CLI 또는 SDK를 활용해 학습에 필요한 피처를 **Offline Store(S3)**에 materialize
    - 실시간 예측 API 호출 시 필요한 피처를 **Online Store(Redis)**에 materialize하여 fetch
    - 피처 정의, 저장 위치, TTL, 버전 등을 포함한 **모든 메타데이터는 PostgreSQL에 저장**
- **선정 이유**:
    1. **피처 일관성 보장 및 자동화**
        - 학습 시점과 서빙 시점에 동일한 피처 정의 및 버전을 보장해 **training/serving skew 방지**
        - `materialize`, `materialize-incremental`, `fetch_online_features()` 등의 기능을 통한 **온라인/오프라인 스토어 자동 동기화**
    2. **MLOps 파이프라인과의 통합성**
        - **Airflow, MLflow, Redis, S3, PostgreSQL 등과 공식 연동**
        - Python 기반 SDK 제공으로 데이터 파이프라인 및 모델 서빙 흐름 내 자동화 가능
    3. **운영 및 유지보수의 간소화**
        - 피처 정의 파일(yaml 또는 Python) 하나로 **전체 파이프라인 관리 가능**
        - TTL 관리, 배포 주기 설정 등 실시간 피처 캐싱 환경 제어
    4. **실무 적용 경험 기반 도구**
        - Uber, Gojek 등 글로벌 MLOps 환경에서 검증된 도구
        - OSS 기반으로 커뮤니티 및 확장성 확보

### 🧪 도구 선정 비교:

| 항목 | Feast | Tecton | Hopsworks | SageMaker Feature Store | DBT + 수동 구현 |
| --- | --- | --- | --- | --- | --- |
| OSS 여부 | ✅ 완전 공개 | ❌ 유료 | ✅ 일부 무료 | ❌ AWS 종속 | ✅ |
| Online/Offline 분리 | ✅ 명확한 구조 | ✅ 가능 | ✅ Spark 기반 | ✅ Glue 기반 | ⛔ 수동 처리 |
| MLOps 연동성 | ✅ Airflow, MLflow 등 공식 | ✅ 일부 연동 | ✅ Spark 필수 | ✅ AWS 기반 도구와 연동 | ❌ |
| 유지보수 용이성 | ✅ CLI + Python SDK | ⛔ 설정 복잡 | ⛔ 학습 필요 | ⛔ AWS에 종속 | ⛔ 버전 관리 어려움 |
| 실무 적용 사례 | ✅ Uber, Gojek, GO-FOOD | ✅ Netflix 등 | ✅ EU 기업 일부 | ✅ Amazon 실무 | ⛔ 없음 |

<aside>
💡

## **Feature Store, Feast 도입의 가치**

### 🔴 Feast 없이 PostgreSQL만 사용할 경우의 한계

- 피처 정의와 버전 정보가 코드나 쿼리 안에 하드코딩됨 → **협업 및 재사용 어려움**
- 학습 데이터와 실시간 서빙 데이터 간 불일치(skew)가 발생할 가능성 ↑
- 피처 TTL, 배치 materialize, 실시간 캐싱 등 **자동화 기능 부재**
- Online/Offline Store를 수동으로 구분/연동해야 함 → 유지보수 및 오류 가능성 ↑

### ✅ Feast 도입 시 효과

- **피처를 코드화하여 정의 및 추적 가능** (Feature View, Entity 등)
- Offline/Online Store 간 materialize 자동화 → 학습/서빙 일관성 유지
- Redis/S3/PostgreSQL 연동을 통해 피처 저장소 구성 자동화
- SQL/Python 기반으로 누구나 쉽게 피처 정의 및 수정 가능
- 피처 단위로 재사용 가능 → **중복 정의 제거, 생산성 향상**

### 🔄 Feast 내 Online vs Offline Store 구조 구분

| 항목 | Offline Store (S3) | Online Store (Redis) |
| --- | --- | --- |
| 목적 | 배치 학습용 피처 저장 | 실시간 서빙용 피처 저장 |
| 저장 방식 | 파일 기반 (.parquet/.csv) | Key-Value 인메모리 구조 |
| 사용 시점 | 학습 파이프라인 (Train set) | API 요청 시 (Serving) |
| TTL 관리 | 없음 (지속 저장) | TTL 설정 필수 |
| Materialize 방식 | feast materialize | feast materialize-incremental |

### 🧪 실무 시나리오 예시

1. **피처 엔지니어링 단계**:
    - TMDB + IMDB 데이터 → SQL 전처리 → `feature_movies` 테이블 생성
    - 해당 테이블을 기반으로 Feature View 정의 후 등록
2. **모델 학습 단계**:
    - Feast를 통해 `feature_movies`에서 Offline 피처를 추출하여 S3 저장
    - 모델 학습은 S3에서 로딩된 `.parquet` 기반으로 진행
3. **실시간 예측 단계**:
    - 모델 학습 시 사용된 동일 피처를 Redis에 materialize
    - API 서버(FastAPI)가 실시간 요청 수신 시 `fetch_online_features()`로 Redis에서 피처 fetch 후 예측 반환
4. **배포 및 유지보수**:
    - Feature View 수정 → 다시 materialize만 하면 전 시스템에 자동 반영
    - TTL 등 실시간 서빙 피처 갱신 주기 설정도 간편
</aside>

### 📝 최종 평가 및 선택 사유 요약

> Feast는 학습과 서빙의 피처 일관성, 재사용성, 자동화를 동시에 제공하며,
> 
> 
> 특히 **Redis, S3, PostgreSQL과의 구조적 연동성**으로 인해 MLOps 실습 환경에 최적화된 OSS입니다.
> 
> Tecton, Hopsworks, SageMaker 등 대안은 비용/설정/플랫폼 종속성 등의 이유로 본 프로젝트의
> 
> **학습용 경량 아키텍처와 DevOps 중심 운영 체계에 적합하지 않음**이 판단되어 제외하였습니다.
> 
> OSS 생태계, 기술적 구조, 파이프라인 유연성을 종합적으로 고려할 때
> 
> **Feast는 프로젝트의 핵심 Feature Store로서 최적의 선택이었음**을 명확히 정의합니다.
> 

---

## 3️⃣ Redis (Feast Online Store)

- **역할**:
    
    실시간 예측 시 필요한 피처 조회 / 실시간 캐시 / Online Feature 저장소 (Feast 연동용 In-Memory Store)
    
- **사용처**:
    - **FastAPI 모델 API 서버**에서 사용자 요청 수신 시 `fetch_online_features()` 함수로 **Redis에서 피처를 실시간 조회**
    - Feast materialize-incremental 명령을 통해 **전처리된 피처를 Redis에 저장**
    - 사용자 행동 로그, 최신 평점, 최근 클릭 정보 등 **실시간 변화가 필요한 피처들을 저장**
    - TTL(Time To Live)을 설정하여 **일정 시간이 지난 피처 자동 만료 및 갱신** 가능
- **선정 이유**:
    1. **초저지연 실시간 응답**
        - In-Memory 기반 저장 구조로 **ms 단위의 초고속 피처 조회 가능**
        - 실시간 예측 서비스에서 가장 중요한 **속도 조건 충족**
    2. **Feast와의 공식 통합**
        - Feast에서 공식적으로 지원하는 Online Store → 설정 및 연동 간단
        - `redis_config:` 항목으로 Store 정의 가능, `materialize-incremental` 실행만으로 Redis 자동 업데이트
    3. **TTL, 자동 갱신 등 서빙 최적화 기능**
        - 피처별 TTL 설정을 통해 **오래된 피처 자동 폐기 가능**
        - materialize 스케줄링 설정을 통해 **배치 or 실시간 갱신 체계 구현 가능**
    4. **운영 및 테스트 편의성**
        - 컨테이너(Docker) 환경에서 Redis 단독 실행 가능
        - 로컬, 개발, 운영 환경에서 모두 **일관된 방식으로 적용 가능**
        - Python, CLI, Feast 모두에서 지원되어 실험 환경 구성 및 API 연동 간편

### 🔄 Redis 없이 PostgreSQL만 사용할 경우 한계

- PostgreSQL은 디스크 기반 구조로 인해 **실시간 예측 요청에 대한 응답 속도가 느림**
- TTL, 캐시 만료 등 **서빙 최적화 기능 부재**
- 예측 요청마다 디스크 기반 테이블을 조회해야 하므로 **부하 및 지연 시간 증가**
- Feast는 PostgreSQL을 Online Store로 지원하지 않음 → **공식 연동 불가**

### ✅ Redis 도입 후 기대 효과

- **ms 단위 실시간 피처 조회로 예측 속도 향상**
- TTL 설정을 통한 피처 최신성 보장
- Redis 내 피처 materialize 후 API 요청 수신 시 **FastAPI → Redis → 모델 예측 흐름 구축**
- 실시간 온라인 환경에서 스케일 확장 시 Redis Cluster 활용 가능

### 🧠 실무 적용 예시

| 상황 | 기존 방식(PostgreSQL) | Redis 도입 후 |
| --- | --- | --- |
| 실시간 예측 요청 | SQL 쿼리 실행 후 피처 조회 (수십~수백 ms) | In-memory fetch (수 ms 이내) |
| 피처 갱신 | 직접 update 필요 | TTL 기반 자동 만료 + materialize-incremental |
| 연동 방식 | 수동 SQL + API 작성 | Feast CLI 또는 Python SDK로 자동 materialize |
| 운영 부담 | 트랜잭션 관리 필요, 느린 응답 | 경량 Redis 서버로 분리 운영 가능 |

### 🧪 도구 선정 비교:

| 항목 | Redis | DynamoDB | PostgreSQL | Cassandra | Memcached | Elasticsearch |
| --- | --- | --- | --- | --- | --- | --- |
| 저장 구조 | ✅ In-Memory (K/V) | ✅ K/V NoSQL | ⛔ 테이블 기반 (디스크) | ✅ 분산 K/V | ✅ In-Memory | ✅ 분산 검색엔진 |
| TTL 기능 | ✅ 지원 (기본 기능) | ✅ 지원 | ⛔ 미지원 | ✅ 설정 가능 | ✅ 제한적 | ⛔ 목적 부적합 |
| Feast 공식 연동 | ✅ 지원 (online_store) | ⛔ 비공식 | ⛔ 미지원 | ⛔ 미지원 | ⛔ 미지원 | ⛔ 미지원 |
| 응답 속도 | ✅ 수 ms | ✅ 수 ms (단 비용↑) | ⛔ 수십~수백 ms | ⛔ 복잡, 느림 | ✅ 빠름 (기본 캐시) | ⛔ 검색 특화 |
| 운영 복잡도 | ✅ 낮음 | ⛔ AWS 구성 필요 | ✅ 중간 | ⛔ 클러스터 운영 필요 | ✅ 낮음 | ⛔ 높은 설정 난이도 |
| 실시간 예측 적합성 | ✅ 최적 | ✅ 가능 | ⛔ 미적합 | ⛔ 설정 어려움 | ⛔ 캐시용 한정 | ⛔ 분석 용도 특화 |

### 📝 최종 평가 및 선택 사유 요약

> Redis는 실시간 피처 서빙 환경에 최적화된 In-Memory 저장소로,
> 
> 
> **속도, TTL, Feast 공식 연동성** 측면에서 Online Feature Store로 최상의 선택지입니다.
> 
> DynamoDB, PostgreSQL, Cassandra, Memcached 등 다양한 대안이 있었지만,
> 
> - DynamoDB: 연동이 복잡하고 비용 부담
> - PostgreSQL: 실시간 요청에 적합하지 않고 연동 미지원
> - Cassandra: 분산 시스템 구성/운영이 과도함
> - Memcached: TTL 기능은 있지만, 영속성/관리 도구 부족
> 
> **단일 컨테이너 구성에서도 Feast materialize로 자동 업데이트가 가능하고,**
> 
> 실시간 서빙 환경에서의 **응답 속도와 TTL 기능이 요구되는 프로젝트 요구사항에 가장 부합**하여 최종 선택되었습니다.
> 

---

## 4️⃣ MLflow (Machine Learning Flow)

- **역할**:
    
    ML 실험 기록 / 모델 학습 결과 추적 / 모델 버전 레지스트리 / 모델 배포 연계
    
- **사용처**:
    - ML 모델 학습 과정에서:
        - `log_param()`, `log_metric()`, `log_artifact()` 등으로 **실험 이력 자동 기록**
        - 예: 하이퍼파라미터, 성능 지표(MAE, RMSE 등), 학습 시간, 환경 정보 등
    - 실험 반복 시:
        - **여러 버전 간 시각화/비교 UI 제공**으로 최적 성능 모델 탐색
    - 학습 완료 후:
        - `.pkl`, `.onnx`, `.pt` 등 **모델 파일 아티팩트를 S3에 저장**
        - 해당 모델을 **MLflow Model Registry**에 등록하고 버전 관리
    - API 서빙 시:
        - `mlflow.pyfunc.load_model()`로 **특정 버전 모델 불러와 예측에 사용**
- **선정 이유**:
    1. **완전한 실험 관리 시스템**
        - 코드 외부에서 실험 정보를 자동 관리해주므로 **실험 재현성 보장**
        - CSV 또는 텍스트로 실험 관리하는 수작업보다 정확성과 추적 가능성이 월등
    2. **모델 레지스트리와 통합 제공**
        - 단순 실험 기록 도구가 아닌 **학습 후 모델 배포까지 고려된 구조**
        - `stage: production`, `version: v1` 등의 레이블링 가능
    3. **다양한 도구 연동성**
        - Airflow 태스크 내 MLflow Tracking 자동 호출 가능
        - S3를 Artifact Store로 지정 가능
        - PostgreSQL을 Tracking backend로 설정 가능
        - FastAPI와도 자연스럽게 연계하여 **서빙 시 모델 로드 자동화**
    4. **운영/실습 모두에 적합**
        - 경량 구성으로 로컬 개발에도 적합하며, 대형 클러스터에서도 확장성 보유
        - SQLite, PostgreSQL, MySQL 등 다양한 RDB 지원
        - 웹 UI 제공 → 실험 리스트, 그래프, 버전 등 시각화 가능

### 🔁 실습 흐름 예시

```python
import mlflow

with mlflow.start_run():
    mlflow.log_param("n_estimators", 100)
    mlflow.log_param("max_depth", 10)
    mlflow.log_metric("mae", 0.139)
    mlflow.log_artifact("model.pkl")
```

- 모델 학습 시 위와 같이 API로 로그 기록 → 자동으로 웹 UI 및 S3에 기록
- 이후 MLflow Registry에 등록 후 `v1`, `Production` 등 태깅 가능

### 🧪 도구 선정 비교

| 항목 | **MLflow** | Weights & Biases | Comet ML | DVC | SageMaker Experiments | Neptune.ai | TensorBoard |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 라이선스/비용 | ✅ 오픈소스 | Freemium | Freemium | ✅ 오픈소스 | ❌ AWS 종속 | Freemium | ✅ 오픈소스 |
| 실험 결과 추적 | ✅ 강력 | ✅ | ✅ | ❌ (파일 중심) | ✅ | ✅ | 제한적 (로그) |
| 시각화 UI | ✅ | ✅ | ✅ | ❌ | ✅ | ✅ | 제한적 |
| 모델 레지스트리 | ✅ 포함 | ❌ | ✅ | ❌ | ✅ | ✅ | ❌ |
| 로컬 설치 | ✅ 가능 | ❌ | ❌ | ✅ | ❌ | ❌ | ✅ |
| S3 연동 | ✅ 공식 | ✅ | ✅ | ❌ | ✅ | ✅ | ❌ |
| CI/CD 연계 | ✅ REST API | ✅ | ✅ | ✅ | 제한적 | ✅ | ❌ |
| MLOps 도구 연동 | ✅ Airflow, Feast 등 | ❌ | 제한적 | ❌ | ❌ | 제한적 | ❌ |

### 📝 최종 평가 및 선택 사유 요약

> MLflow는 본 프로젝트에서 모델 학습 → 실험 기록 → 아티팩트 저장 → 모델 버전 등록까지
> 
> 
> 하나의 플랫폼 내에서 통합 처리 가능한 유일한 오픈소스 도구입니다.
> 
> Feast, Airflow, FastAPI, PostgreSQL, S3 등과의 **공식 연동성과 확장성**을 통해
> 
> **MLOps 전체 흐름을 하나의 Tracking UI로 통제**할 수 있는 이점이 큽니다.
> 
> 특히 다른 대안인 W&B, Comet, DVC, Neptune 등은 **유료/웹 전용/연동성 부족/레지스트리 미포함** 등의 단점 존재.
> 
> **로컬 테스트부터 실무 파이프라인까지 일관된 환경 구성과 실험 추적 자동화를 동시에 확보할 수 있어**
> 
> **MLflow가 본 프로젝트에 가장 적합한 실험 관리 도구로 최종 채택되었습니다.**
> 

---

## 5️⃣ Airflow (Workflow Orchestration & Scheduler)

- **역할**:
    
    ETL / ML 파이프라인 작업 자동화 / 데이터 흐름 관리 / 정기 실행 스케줄링 / MLOps 통합 제어
    
- **사용처**:
    - 외부 데이터 수집 주기 설정 (예: TMDB/IMDB API)
    - 데이터 전처리 → PostgreSQL 저장 → S3 변환 저장 → Feast materialize
    - 모델 학습 및 실험 기록(Mlflow) 자동 실행
    - 전체 작업을 DAG(Directed Acyclic Graph) 단위로 정의하여 **시간 기반, 조건 기반, 이벤트 기반**으로 자동 실행
    - 각 Task별 실패/성공 여부 및 로그 기록 → Slack 알림, 재시도 등 자동 대응 가능
- **선정 이유**:
    1. **ETL & ML 작업 자동화 핵심 도구**
        - 데이터 수집 → 피처 생성 → 모델 학습까지 흐름을 한 번에 구성 가능
        - 각 단계(Task)를 Python 함수, Shell Script 등 다양한 방식으로 정의 가능
    2. **모듈화된 DAG 설계 지원**
        - DAG 단위로 작업 흐름 설계 → 시각화 UI로 전체 파이프라인 상태 모니터링
        - `@daily`, `@weekly`, `cron` 등 유연한 주기 설정 가능
    3. **MLOps 전체 흐름 통합 가능**
        - Airflow에서 Feast materialize, MLflow run, Redis materialize까지 자동 호출 가능
        - S3 업로드, DB 로딩 등도 BashOperator, PythonOperator로 쉽게 구현 가능
    4. **확장성과 실무 호환성 우수**
        - KubernetesExecutor, CeleryExecutor 등으로 확장 가능
        - Postgres, S3, Redis, Docker 등 모든 도구와 연동 가능한 플러그인 구조
        - 실무에서도 가장 널리 쓰이는 스케줄러로 **기술 호환성과 교육 자료 풍부**
    5. **팀 협업 및 유지보수 편의**
        - DAG 정의를 코드로 작성하므로 버전관리(Git) 가능
        - 실습 환경에서는 로컬 + SQLite 기반으로 빠르게 테스트 가능

### 🧪 도구 선정 비교

| 항목 | **Airflow** | Prefect | Dagster | Luigi | Kubeflow Pipelines | Azkaban |
| --- | --- | --- | --- | --- | --- | --- |
| 배포 유연성 | ✅ Docker/K8s/로컬 모두 가능 | ✅ Cloud/로컬 | ✅ Python 기반 | ⛔ 단일 서버 위주 | ⛔ K8s 전용 | ⛔ Hadoop 기반 |
| DAG 시각화 | ✅ 강력한 UI | ✅ 존재 | ✅ 강력함 | ⛔ 거의 없음 | ✅ Pipeline View | ⛔ 텍스트 위주 |
| 연동성 | ✅ 모든 도구 연계 (S3, MLflow 등) | ⛔ Prefect 전용 구조 많음 | ✅ Type 기반 연계 우수 | ⛔ 제한적 | ✅ TF 기반 연동 | ⛔ Hadoop 중심 |
| 학습 곡선 | ⚠️ 중급 이상 | ✅ 쉬움 | ⚠️ 중간 | ✅ 쉬움 | ⛔ 복잡 (YAML + TF) | ⛔ 매우 제한적 |
| OSS 생태계 | ✅ 매우 활발 | ✅ 커뮤니티 증가 | ✅ 빠르게 성장 중 | ⛔ 축소됨 | ⛔ 일부 기업 전용 | ⛔ 오래됨 |
| 실무 사용성 | ✅ 가장 널리 사용됨 | ✅ 스타트업 중심 | ✅ 분석 중심 사용 | ⚠️ 마이너 | ⛔ 엔터프라이즈 중심 | ⛔ 낮음 |

### 📝 최종 평가 및 선택 사유 요약

> Airflow는 MLOps 워크플로우를 **“시간/조건 기반으로 자동화”**할 수 있는 가장 널리 사용되는 OSS 도구입니다.
> 
> 
> 데이터 수집, 전처리, 피처 스토어 업데이트, 모델 학습, 실험 기록, 실시간 서빙 준비 등
> 
> **MLOps의 모든 단계를 통합 제어할 수 있는 중앙 오케스트레이션 툴**로 적합합니다.
> 
> 다른 대안인 Prefect, Dagster, Luigi, Kubeflow Pipelines 등은
> 
> - Prefect: 도입 쉬우나 API 위주, OSS 통합 어려움
> - Dagster: 분석/ETL 중심에 강하나 MLflow/Feast 연계 약함
> - Kubeflow Pipelines: 전용 클러스터 필요, 학습 곡선 가파름
> - Luigi, Azkaban: 구형 구조, MLOps 연동에 제약 많음
> 
> **Airflow는 확장성, 연동성, 학습 자료, 팀 협업 측면에서 최적의 오케스트레이션 도구로 최종 선택**되었습니다.
> 

---

## 6️⃣ Kafka (실시간 이벤트 스트리밍 플랫폼)

- **역할**:
    
    실시간 데이터 스트리밍 처리 / 사용자 이벤트 수집 / 비동기 메시지 전달 / 데이터 흐름 브로커
    
- **사용처**:
    - 영화 평가, 클릭, 시청 시작/종료, 추천 결과 클릭 등의 **사용자 행동 로그**를 Kafka Topic으로 송신
    - Kafka Consumer로 Redis / PostgreSQL / Logstash / Alertmanager 등으로 실시간 전달
    - 실시간 피처 생성 또는 서빙 시점의 **스트리밍 파이프라인 구성 요소**로 사용
    - 향후 확장 시, Kafka Stream API 또는 Spark Streaming 연계로 실시간 분석도 가능
- **선정 이유**:
    1. **대용량 고속 데이터 스트리밍 최적화**
        - 초당 수십만 건 이상 이벤트 처리 가능
        - 디스크 기반 로그 저장 및 소비 방식으로 **내구성과 확장성 확보**
        - 메시지 순서 보장 (파티션 단위), **데이터 유실 위험 최소화**
    2. **실시간 MLOps 파이프라인 구성 가능**
        - 사용자 행동 이벤트를 기반으로 실시간 피처 생성 가능
        - Feast와 연계하여 Redis materialize를 실시간화
        - Logstash로 연계하여 ELK(Elasticsearch, Logstash, Kibana) 스택과 통합
        - Prometheus, Alertmanager 등과도 연계 가능하여 **모니터링 및 경보** 자동화 가능
    3. **다양한 연동성과 커뮤니티 생태계**
        - Python, Java, Scala, Go 등 다언어 지원
        - Kafka Connect, Kafka REST Proxy, Confluent 등의 생태계 확장성 보유
        - Airflow, MLflow, Feast, Grafana 등과도 **간접 또는 직접 연동 가능**

### 🧪 도구 선정 비교

| 항목 | Kafka | RabbitMQ | Redis Streams | Apache Pulsar | NATS | AWS Kinesis |
| --- | --- | --- | --- | --- | --- | --- |
| 처리 성능 | ✅ 고속 대용량 | ⚠️ 중간 | ⚠️ 메모리 의존 | ✅ 고성능 분산 | ✅ 경량 빠름 | ✅ 클라우드 고속 |
| 메시지 보존 | ✅ 디스크 기반, 설정 가능 | ⚠️ 짧은 TTL | ⚠️ 제한적 | ✅ 디스크 기반 | ⚠️ 짧음 | ✅ 가능 |
| 순서 보장 | ✅ 파티션 내 보장 | ✅ 보장 | ⚠️ 약함 | ✅ 강력 | ⚠️ 보장 안됨 | ✅ 가능 |
| 확장성 | ✅ 수평 확장 쉬움 | ⚠️ 제약 많음 | ⚠️ 제한적 | ✅ 클러스터링 우수 | ⚠️ 한계 | ✅ AWS 종속 확장 |
| 실시간 분석 | ✅ 가능 (Stream API) | ⚠️ 큐 중심 | ⚠️ 단순 구조 | ✅ 고성능 처리 | ⚠️ 별도 구축 필요 | ✅ AWS 서비스 기반 |
| MLOps 연동성 | ✅ Feast/ELK/Alert 연계 | ⚠️ 실시간 연계 어려움 | ⚠️ 수동 설정 필요 | ⚠️ 연동 플러그인 필요 | ⚠️ 연동 자료 적음 | ✅ AWS 기반 MLOps에 적합 |
| 도입 난이도 | ⚠️ 중급 이상 | ✅ 쉬움 | ✅ 쉬움 | ⚠️ 복잡 | ✅ 경량화 쉬움 | ✅ AWS 연동 간편 |

### 📝 최종 평가 및 선택 사유 요약

> Kafka는 대용량 실시간 메시지 처리에 최적화된 플랫폼으로
> 
> 
> MLOps 환경에서 사용자 로그 수집, 실시간 피처 업데이트, 모니터링 연계까지
> 
> **데이터 흐름의 중심 허브 역할**을 수행합니다.
> 
> RabbitMQ, Redis Streams, Pulsar, NATS 등 여러 대안과 비교했을 때,
> 
> - Redis Streams: 메모리 기반으로 규모 확장 어려움
> - RabbitMQ: 큐 기반으로 실시간 스트리밍엔 부적합
> - Pulsar: 설정 복잡, 대기업 환경에 적합
> - NATS: 초경량 구조이나 데이터 유실 가능성 큼
> - Kinesis: AWS 전용이라 클라우드 종속성 강함
> 
> 본 프로젝트는 다양한 OSS 도구(Airflow, Feast, ELK, Prometheus 등)를 활용하고 있으며
> 
> Kafka는 이들과의 **호환성과 확장성, 안정성**을 모두 만족하므로
> 
> **실시간 스트리밍 기반 MLOps 아키텍처에서 필수 도구로 최종 채택**되었습니다.
> 

---

## 7️⃣ ELK Stack (Elasticsearch + Logstash + Kibana)

- **역할**:
    
    로그 수집(Logstash), 색인 및 검색(Elasticsearch), 시각화 및 대시보드(Kibana)를 제공하는
    
    **통합 로그 모니터링 및 분석 플랫폼**
    
- **사용처**:
    - FastAPI / Airflow / MLflow / Feast 등 **각 도구에서 발생하는 로그**를 Logstash로 수집
    - 수집된 로그를 Elasticsearch에 **색인 및 저장**하여 검색 가능하게 구성
    - Kibana를 통해 **시각화 및 대시보드 생성**, 에러/성능/상태 모니터링
    - 실시간 MLOps 운영 환경에서 로그 기반 **이상 탐지, 경고 트리거(Alertmanager 연동)**에 활용
- **선정 이유**:
    1. **로그 데이터에 대한 고속 검색/색인 지원**
        - Elasticsearch는 역색인 기반으로 **대규모 로그를 빠르게 검색/조회** 가능
        - 텍스트 기반 로그에서 조건/키워드/시간대별 **복합 쿼리 지원**
    2. **모듈형 구조와 확장성**
        - Logstash는 다양한 소스에서 **로그 수집/필터링/정제** 가능
        - Kibana는 실시간 대시보드, 필터링, 탐색 UI 제공으로 **운영자 중심 UX 최적화**
        - 전체 구조가 Docker, K8s 기반 환경에 쉽게 배포 가능
    3. **오픈소스 기반으로 비용 부담 없이 사용 가능**
        - 유료 SaaS(Splunk, Datadog) 대비 **강력한 기능 제공하면서도 비용 효율성 우수**
        - 다양한 커뮤니티 플러그인, APM, Beat 등과 연계 확장 가능
    4. **MLOps 실무 도구들과 연계성 우수**
        - Airflow 태스크 로그, MLflow UI 로그, FastAPI 요청 응답 로그 등을 모두 **통합 수집/조회**
        - Alertmanager 또는 Kafka 연동으로 **자동 경고 시스템 구현 가능**
        - Prometheus와도 병렬 사용 가능 (로그 vs 메트릭 역할 구분)

### 🧪 도구 선정 비교:

| 항목 | ELK Stack | Loki + Grafana | Graylog | Splunk | Fluentd + Kibana | Datadog |
| --- | --- | --- | --- | --- | --- | --- |
| 라이선스 | ✅ 오픈소스 | ✅ 오픈소스 | ✅ 오픈소스 | ❌ 유료 | ✅ 오픈소스 | ❌ 유료 |
| 로그 수집 | ✅ Logstash | ✅ Promtail | ✅ 자체 모듈 | ✅ 강력 | ✅ Fluentd | ✅ Agent |
| 색인/검색 | ✅ 고속 역색인 | ⚠️ 제한적 | ⚠️ 보통 | ✅ 매우 강력 | ⚠️ 제한적 | ✅ 고급 |
| 시각화 UI | ✅ Kibana | ✅ Grafana | ⚠️ 보완 UI | ✅ 우수 | ✅ Kibana | ✅ 자체 UI |
| 구성 난이도 | ⚠️ 중간 | ✅ 쉬움 | ⚠️ 중간 | ❌ 복잡 | ⚠️ 복잡 | ✅ 손쉬움 |
| 실무 적합성 | ✅ OSS 표준 | ✅ 메트릭/로그 혼합 | ⚠️ 제한적 채택 | ✅ 대기업 사용 | ⚠️ DevOps 중심 | ✅ SaaS 기반 |
| 비용 구조 | ✅ 무료 사용 가능 | ✅ 무료 | ✅ 무료 | ❌ 유료 | ✅ 무료 | ❌ 월과금 |

### 📝 최종 평가 및 선택 사유 요약

> ELK Stack은 로그 수집-색인-분석-시각화를 모두 포함하는 통합 솔루션으로,
> 
> 
> MLOps 실습/운영 환경에서 발생하는 다양한 로그를 **중앙 집중식으로 관리**할 수 있게 해줍니다.
> 
> 특히,
> 
> - FastAPI 예측 로그
> - Airflow 태스크 실행 로그
> - MLflow 실험 추적 로그
> - Kafka 이벤트 로그
> 
> 모두를 Logstash → Elasticsearch → Kibana로 연결 가능하며,
> 
> 로그의 **색인 + 검색 + 시각화**가 동시에 필요한 MLOps 워크플로에서 **실시간 이상 탐지, 디버깅, 운영지표 확인**에 큰 장점을 가집니다.
> 
> Splunk, Datadog 등 상용 대안과 비교해도 **오픈소스 기반으로 충분한 기능을 제공**하고,
> 
> Loki, Fluentd, Graylog 등과 비교해도 **색인 및 검색 강점, 대시보드 UX 측면에서 우위를 가져**
> 
> 본 프로젝트에서 **가장 실무 친화적인 로그 분석 도구로 채택**되었습니다.
> 

---

## 8️⃣ Prometheus

- **역할**:
    
    메트릭 수집 및 모니터링 도구로,
    
    **애플리케이션, 컨테이너, 노드 등에서 발생하는 성능 지표를 주기적으로 수집(Pull 방식)**하고,
    
    **Alertmanager와 연동하여 실시간 상태 감시 및 알림 자동화** 가능
    
- **사용처**:
    - Kubernetes 기반 컨테이너 환경에서 각 서비스(Pod, Node)의 **CPU, Memory, Network 사용량** 수집
    - FastAPI의 응답 시간, 에러율, 요청 처리량 등의 **애플리케이션 레벨 메트릭 수집**
    - Airflow, MLflow 등의 **서비스 상태, 성공/실패율, 스케줄링 정상 여부** 모니터링
    - Alertmanager와 함께 사용하여 **지표 기반 자동 알림 시스템 구성**
- **선정 이유**:
    1. **MLOps 인프라 구성에서 모니터링은 필수**
        - ML 서비스 운영 중 **성능 저하, 시스템 부하, API 장애**를 빠르게 감지하기 위해 지표 수집 필요
        - Prometheus는 가장 보편적이며 경량화된 **컨테이너 모니터링 표준 도구**
    2. **Kubernetes 및 Docker와의 높은 호환성**
        - Service Discovery 기능으로 **자동으로 노드/서비스 탐색**
        - Helm Chart를 이용한 손쉬운 배포
        - Kubernetes Metrics Server, Node Exporter, cAdvisor 등과의 **통합 수집 구조**
    3. **Grafana와의 완벽한 연동**
        - Prometheus의 쿼리언어(PromQL)를 통해 **커스터마이징된 실시간 대시보드 구성**
        - 여러 프로젝트 상태, 서버 상태를 한 눈에 파악 가능
    4. **알림 자동화와 장애 대응**
        - Alertmanager를 통해 **Slack, Email, Telegram, Webhook 등으로 장애 실시간 알림 전송**
        - 조건 기반 알림 정책으로 MLOps 파이프라인 상태 자동 감시 가능
    5. **오픈소스 기반으로 확장성 및 비용 효율성 확보**
        - 자체 서버에서 구동 가능하며, 클라우드 및 로컬 환경 모두 지원
        - Grafana 및 Alertmanager와 함께 통합 구성 시, 별도 SaaS 없이 완전한 **내부 모니터링 체계 구성 가능**

### 🧪 도구 선정 비교:

| 항목 | **Prometheus** | Zabbix | Datadog | New Relic | InfluxDB | Nagios |
| --- | --- | --- | --- | --- | --- | --- |
| 수집 방식 | **Pull 방식 (Scrape)** | Agent 설치 필요 | Agent (SaaS) | Agent (SaaS) | Push / Pull | Agent |
| Kubernetes 연동 | ✅ 공식 지원 | ⛔ 별도 구성 필요 | ✅ (요금제 필요) | ✅ | ⚠️ 제한적 | ⛔ |
| 경량성 | ✅ 매우 가볍고 빠름 | ❌ 무거움 | ✅ (SaaS) | ✅ | ⚠️ 중간 | ⚠️ 무거움 |
| 알림 연계 | ✅ Alertmanager 공식 연동 | Email 중심 | 자체 내장 | 자체 내장 | 설정 필요 | Email 중심 |
| 대시보드 시각화 | ✅ Grafana 공식 연동 | 제한적 UI | 자체 UI | 자체 UI | 자체 UI | 제한적 |
| OSS 여부 | ✅ 완전 오픈소스 | ❌ | ❌ | ❌ | ✅ | ✅ |
| 실무 적용도 | ✅ DevOps/MLOps 표준 | ⚠️ 레거시 중심 | ✅ 기업 사용 ↑ | ✅ | ⚠️ 연구 중심 | ⚠️ 일반 서버 관리용 |

### 📝 최종 평가 및 선택 사유 요약

> Prometheus는 Kubernetes 기반 MLOps 환경에서 가장 표준적인 메트릭 수집 도구로,
> 
> 1. 서비스 성능 감시
> 2. 리소스 부하 탐지
> 3. Alertmanager 연동 자동화
> 
> 를 통해 실시간 운영 상태를 **수치 기반으로 정확하게 추적**할 수 있습니다.
> 
> 다른 대안들(Zabbix, InfluxDB, Datadog 등)은 무겁거나 요금제 제약, 설정 복잡도가 존재하며,
> 
> Prometheus는 OSS 기반이면서도 **K8s, Docker, Grafana, Alertmanager와의 완벽한 통합**이 가능해
> 
> **본 프로젝트의 실시간 관측, 경고 시스템 구현에 최적의 선택지로 최종 채택**되었습니다.
> 

---

## 9️⃣ Grafana

- **역할**:
    
    메트릭 시각화 및 실시간 대시보드 구성 도구.
    
    **Prometheus, Elasticsearch, PostgreSQL, Loki 등 다양한 데이터 소스와 연결 가능**하며,
    
    **MLOps 모니터링 파이프라인에서 관측 지표 시각화** 역할을 담당.
    
- **사용처**:
    - Prometheus로 수집된 Kubernetes, FastAPI, Airflow, Redis 등의 **메트릭을 실시간 시각화**
    - 컨테이너 리소스(CPU, Memory), API 응답 시간, DB 연결 수, 에러율 등의 **서비스 헬스 상태 대시보드 구성**
    - Alertmanager의 알림 트리거 조건을 시각적으로 분석하여 **모니터링 기준 설정**
    - MLflow 실험 결과, Redis 사용량, S3 데이터 접근 지표 등도 통합 시각화 가능
- **선정 이유**:
    1. **MLOps 환경 전반의 관측 시각화에 필수**
        - Prometheus, Loki, Elasticsearch, PostgreSQL 등 다양한 소스를 **동시에 연결** 가능
        - 실시간 대시보드로 **모델 API 상태, 리소스 부하, 시스템 이벤트**를 한눈에 파악
    2. **설정 유연성 및 커스터마이징**
        - PromQL, SQL, Lucene 쿼리 등 다양한 방식으로 지표 쿼리 가능
        - JSON 대시보드 정의 → 템플릿화 → 재사용 가능
        - 변수(Variables), 필터, 조건부 색상 등 **인터랙티브 구성** 지원
    3. **시스템 통합성**
        - Alertmanager와 연계한 **알림 발생 기준 시각화**
        - FastAPI 로그(Grafana + Loki), Prometheus 메트릭, Elasticsearch 인덱스 모두 대시보드에 통합 가능
        - **ELK 스택과의 공존 및 역할 분담 가능** (ELK는 로그 중심 / Grafana는 지표 중심)
    4. **오픈소스 기반 운영 효율**
        - 무제한 사용자 사용 가능, 로컬 서버/클라우드 모두 설치 가능
        - Helm Chart, Docker Compose 등을 통한 **경량화된 설치**
        - 무료 플러그인(Clock, Pie Chart, World Map 등)을 통해 기능 확장 가능

### 🧪 도구 선정 비교:

| 항목 | **Grafana** | Kibana | Tableau | Power BI | Redash | Metabase |
| --- | --- | --- | --- | --- | --- | --- |
| 지원 데이터 소스 | ✅ Prometheus, Elastic, PostgreSQL 등 | ⛔ Elastic 전용 | ✅ SQL, CSV | ✅ SQL, CSV | ✅ SQL 기반 | ✅ SQL 기반 |
| 실시간 시각화 | ✅ (ms 단위) | ✅ (Log 중심) | ⛔ (수동 업데이트) | ⛔ (시간차 존재) | ⚠️ 제한적 | ⚠️ 제한적 |
| 커스터마이징 | ✅ 매우 유연 | ✅ 중간 | ✅ 고급 | ✅ 고급 | ⚠️ 제한적 | ⚠️ 제한적 |
| 설치/운영 복잡도 | ✅ 경량 (Docker/Helm) | ⚠️ 중간 | ❌ 무거움 | ❌ 무거움 | ✅ 간단 | ✅ 간단 |
| 라이선스 | ✅ 완전 오픈소스 | ✅ 오픈소스 | ❌ 유료 | ❌ 유료 | ✅ 오픈소스 | ✅ 오픈소스 |
| 실무 적용도 | ✅ DevOps/MLOps 표준 | ✅ 로그 기반 운영 | ✅ 대시보드 중심 | ✅ 사내 BI 보고용 | ⚠️ 내부 쿼리 분석 | ⚠️ 내부 쿼리 분석 |

### 📝 최종 평가 및 선택 사유 요약

> Grafana는 Prometheus 기반 메트릭 시각화의 사실상 표준 도구로,
> 
> - 다양한 데이터 소스 연계
> - 대시보드 템플릿 기반 시각화
> - 실시간 감시 및 모니터링 알림 시각화
> 
> 등의 장점을 바탕으로, **FastAPI 응답 시간, 모델 예측 지연, Redis 캐시 상태 등 MLOps 전반 상태를 빠르게 감시하고 대응**할 수 있습니다.
> 
> Kibana, Tableau, Power BI 등의 대안은 각각 로그 전용, 유료 정책, 실시간 미지원 등의 한계가 있으며,
> 
> 특히 **MLOps 환경에서는 Prometheus와 통합된 실시간 지표 시각화**가 필수이므로,
> 
> **Grafana는 실시간 운영 대시보드 구성에 있어 최적의 도구로 최종 채택**되었습니다.
> 

---

## 🔟 GitHub Actions

- **역할**:
    
    GitHub 저장소 기반의 **CI/CD 자동화 플랫폼**으로,
    
    코드 커밋/PR 시점에 테스트, 빌드, 배포 과정을 자동 실행하여
    
    **MLOps 파이프라인의 통합 배포 흐름을 구성**하는 역할 수행.
    
- **사용처**:
    - 학습 코드 푸시 또는 PR 발생 시 **자동 테스트** 수행 (예: `pytest`, `flake8`)
    - 모델 서빙용 Docker 이미지 자동 빌드 및 Docker Hub 또는 EC2 서버로 **자동 배포**
    - `.github/workflows/*.yml` 내 YAML 파일로 **CI/CD 파이프라인 선언**
    - EC2, S3, Redis, PostgreSQL 등 외부 자원에 대한 **배포 시점 제어**
    - GitHub Secrets 기반으로 **인증 키, AWS 자격 증명 등 안전하게 관리**
- **선정 이유**:
    1. **GitHub과의 완전한 통합성**
        - 별도 설치 없이 GitHub 저장소에 `Workflows`만 추가하면 자동 작동
        - PR, Push, Tag 기준으로 동작 조건 세분화 가능
        - GitHub Actions 내부에서 **Issues, Releases, Pull Request 상태까지 자동 제어** 가능
    2. **MLOps 자동화 흐름 구축에 최적**
        - 모델 학습/서빙 관련 코드 변경 시점에 맞춰 자동 테스트 및 배포
        - Docker 이미지 빌드 + EC2 배포 자동화
        - 실험 결과 S3 업로드, 배포 버전 태깅 등도 자동화 가능
    3. **운영 편의성과 확장성**
        - Self-hosted runner, AWS/GCP 클라우드 연동 등 고급 구성 가능
        - GitHub Marketplace에 1000개 이상의 액션(Action) 미리 구성되어 있어 재사용 용이
        - Slack, Discord, Telegram 등으로 알림 연동도 가능
    4. **비용 효율성**
        - 퍼블릭 저장소의 경우 무제한 무료
        - 프라이빗 저장소도 월 2000분까지 무료 사용 가능 (기본 플랜)
    5. **실습/교육 환경에서도 적합**
        - GitHub 계정만 있으면 누구나 쉽게 구성 가능
        - 기존 GitHub 기반 코드 리뷰, 협업, 버전 관리와 **CI/CD를 하나로 통합 가능**

### 🧪 도구 선정 비교:

| 항목 | **GitHub Actions** | GitLab CI | Jenkins | CircleCI | Travis CI | Argo CD |
| --- | --- | --- | --- | --- | --- | --- |
| 진입장벽 | ✅ 매우 낮음 (GitHub 기본 통합) | ⚠️ GitLab 기반 | ❌ 설치 필요 | ✅ SaaS 기반 | ❌ 서비스 종료 | ⚠️ K8s 전용 |
| 설치/운영 방식 | GitHub 내 자동 | GitLab 내장 또는 설치형 | 설치 및 유지관리 필요 | 클라우드 | 중단됨 | K8s + GitOps 필요 |
| 파이프라인 작성 방식 | ✅ YAML | ✅ YAML | ✅ Groovy 등 복잡 | ✅ YAML | ✅ YAML | ✅ YAML |
| 외부 도구 연동 | ✅ Docker, EC2, S3 등 | ✅ 유사 | ✅ 자유도 높음 | ✅ AWS/GCP | ❌ 제한적 | ✅ K8s 배포 특화 |
| 알림/통합성 | ✅ Slack, Discord, 텔레그램 등 지원 | ✅ | ✅ | ✅ | ⚠️ | ✅ |
| 실무 적용도 | ✅ GitHub 기반 환경 표준 | ✅ GitLab 기반 조직에 적합 | ⚠️ 유지 보수 필요 | ✅ 스타트업에서 많이 사용 | ❌ 중단됨 | ✅ GitOps 파이프라인용 |

### 📝 최종 평가 및 선택 사유 요약

> GitHub Actions는 GitHub 저장소와 CI/CD를 하나로 통합한 구조로,
> 
> 
> 추가 설치나 설정 없이 **PR 중심의 협업 → 테스트 → 빌드 → 배포 흐름까지 자동화** 가능함.
> 
> Jenkins, CircleCI, GitLab CI, ArgoCD 등 다양한 대안이 있지만,
> 
> - Jenkins: 초기 설치 및 보안 설정 부담, 운영 유지비 높음
> - GitLab CI: GitLab 기반 프로젝트에만 적합
> - CircleCI: 유료 요금제 진입 낮음, 설정 자유도는 높음
> - Argo CD: 쿠버네티스 전용 GitOps 환경에는 적합하지만 복잡
> 
> 본 프로젝트는 **GitHub 기반 협업 중심**으로 운영되며,
> 
> MLOps 흐름의 **서버 자동 배포, 실험 로그 추적, 이미지 버전 관리**까지 통합할 필요가 있어
> 
> **GitHub Actions를 최종 배포 자동화 플랫폼으로 선정**함.
> 

---

## 1️⃣1️⃣ Docker

- **역할**:
    
    MLOps 전반에 사용되는 **서비스 환경을 컨테이너 기반으로 패키징**하여,
    
    실행 환경 이슈 없이 **학습/실험/배포 전 과정을 일관된 형태로 제공**함.
    
    FastAPI, Jupyter, MLflow, Redis, PostgreSQL 등 모든 MLOps 구성요소를 **개별 컨테이너로 구분/관리**.
    
- **사용처**:
    - FastAPI API 서버 → Docker로 컨테이너화하여 배포 자동화
    - MLflow 서버, UI, Tracking 서버 → 각각 Docker 컨테이너로 구분 실행
    - Redis, PostgreSQL, Kafka 등 **모든 외부 서비스의 통합 컨테이너 관리**
    - 실습용 JupyterLab 컨테이너 생성 → 팀원 별 독립 실습 환경 제공
    - `docker-compose.yml`을 통해 MLOps 전체 환경을 코드로 정의
- **선정 이유**:
    1. **환경 통합 및 재현성 보장**
        - 의존성, OS, 패키지 버전 차이를 **Dockerfile 한 줄로 통제**
        - 서버/로컬 간 환경 불일치로 인한 에러 제거 → 코드가 어디서나 동일하게 실행
    2. **MLOps 구성요소의 분리 및 관리 용이**
        - FastAPI, Redis, PostgreSQL, MLflow 등 각 도구를 **독립적인 컨테이너로 구동** 가능
        - 서비스 간 포트, 자원 충돌 없이 운영 가능
        - `docker-compose` 기반으로 MLOps 파이프라인을 YAML로 선언 → 운영 자동화 용이
    3. **학습 및 협업 최적화**
        - 팀원 간 컨테이너 이미지 공유로 실습 환경 일치화
        - GitHub Actions와 함께 배포 자동화 가능
        - 로컬, AWS EC2, GCP, Azure 등 **클라우드 환경 간 이식성 우수**
    4. **생태계 및 커뮤니티 안정성**
        - Docker Hub에 수십만 개의 공식/비공식 이미지 존재
        - `Dockerfile`, `docker-compose`, `buildx`, `volumes`, `network` 등 유연한 설정 가능
        - 대다수 MLOps 도구가 **Docker 기반 이미지 제공** 또는 배포 권장

### 🧪 도구 선정 비교:

| 항목 | **Docker** | Podman | LXC | Singularity | Docker Compose | Bare Metal |
| --- | --- | --- | --- | --- | --- | --- |
| 사용 난이도 | ✅ 쉬움 | ⚠️ 명령어 차이 존재 | ❌ 어렵고 설정 복잡 | ⚠️ HPC 전용 | ✅ 쉬움 (Docker 기반) | ❌ OS 직접 설정 |
| 이미지 관리 | ✅ Docker Hub + CLI | ⚠️ CLI 위주 | ❌ 수동 | ⚠️ 제한적 | ✅ YAML 선언 기반 | ❌ 불가능 |
| 컨테이너 생태계 | ✅ 풍부 | ⚠️ 비교적 작음 | ❌ 제한적 | ⚠️ 연구용 특화 | ✅ Docker 기반 | ❌ 없음 |
| 실무 적용도 | ✅ 가장 흔함 | ⚠️ 일부 기업 | ⚠️ 희소함 | ⚠️ 과학/고성능 연산 특화 | ✅ 실습/교육용 최적 | ❌ 높은 기술 요구 |
| 운영 자동화 연계 | ✅ GitHub Actions, Kubernetes, Airflow 등과 연동 | ⚠️ 별도 설정 필요 | ❌ 불편 | ❌ 불가 | ✅ 자동화 통합 | ❌ 전부 수동 |
| 오픈소스 여부 | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ |

### 📝 최종 평가 및 선택 사유 요약

> Docker는 개발/실험/서버 운영 환경을 완전히 통일할 수 있는 기술로,
> 
> 
> 구성 요소가 많은 MLOps 프로젝트에서 각 요소를 격리/재현/이식 가능하게 해줌.
> 
> 다른 대안(Podman, LXC, Singularity 등)은 각각 일부 목적에 특화되어 있으나,
> 
> - Podman: Docker 호환성이 높지만, Docker Compose 사용 어려움
> - LXC: 초기 설정이 매우 복잡, 실무 적용률 낮음
> - Singularity: HPC 전용이라 일반 MLOps와 거리가 있음
> - Bare Metal: 컨테이너화 미지원 → 협업 및 자동화에 부적합
> 
> 본 프로젝트는 MLOps 구성 요소(MLflow, Feast, FastAPI 등)를
> 
> **효율적이고 통합적으로 실행/배포/협업**하기 위해 Docker를 최종 도구로 선정함.
> 

---

# 🎯 MLOps 파이프라인 3대 서버 아키텍처

![image.png](image.png)

## **1. 서버 아키텍처 개요 및 도구 선정 배경**

| 서버명 | 주 역할 | 핵심 서비스 및 컨테이너 | 주요 도구(선정 이유) |
| --- | --- | --- | --- |
| **서버 1** | 데이터/피처 엔지니어링 + 모델링/학습/관리 | PostgreSQL, Feast, MLflow, Airflow Worker, 데이터/모델 작업 컨테이너 | **PostgreSQL, S3, Feast, MLflow      -** 확장성/표준/호환성/실무 검증 |
| **서버 2** | 오케스트레이션(CI/CD) + Airflow + 모델 서빙 | Airflow Webserver/Scheduler, FastAPI(Serving), SSH, GitHub Actions | **Airflow, GitHub Actions, FastAPI** - 신뢰성/표준/운영편의성 |
| **서버 3** | 모니터링, 로깅, 이벤트 스트리밍, 트리거 관리 | Kafka, Zookeeper, Elastic Stack, Prometheus, Grafana, Alertmanager | **Kafka, ELK, Prometheus, Grafana** - 확장성/시각화/알림/자동화 |

---

## **2. 서버별 상세 워크플로우 및 컨테이너 구조**

---

### **1️⃣ 서버 1: 데이터 & 모델링 서버 (Workhorse)**

### **[1] 데이터 파이프라인**

- **목표:** 원본 데이터(TMDB/IMDB 등) 수집, 정제, 저장
- **순서:**
    1. Airflow Worker가 주기적으로 데이터 수집 Task를 실행
    2. TMDB API, IMDB 데이터셋 등에서 원본 데이터 수집
    3. 전처리/정제(결측치 처리, 타입 변환 등) 수행
    4. **정형 데이터는 PostgreSQL**(Docker 컨테이너) 저장
    5. **Raw/대용량 데이터는 S3**로 아카이빙
- **컨테이너 구조:**
    - `data-extract`, `data-preprocess` 일회성 컨테이너
    - 상시: PostgreSQL
    - **PostgreSQL 컨테이너**
        - **역할:**
            - Airflow/MLflow/Feast의 메타데이터 저장소
            - 데이터 파이프라인(ETL) 중 정형 데이터 저장
        - **입출력 흐름:**
            - Airflow Worker, 데이터 전처리 컨테이너, Feast, MLflow 등 모든 컨테이너와 TCP로 연동
            - 저장: ETL 후 데이터, 실험/파이프라인 이력, 피처 뷰 정의
            - 조회: 피처 추출, 실험 결과/모델 평가 시 데이터 요청
        - **수명:**
            - 상시 운영(서비스 핵심 백엔드)
- 선택 이유
    - **PostgreSQL 선택 이유**
        - MySQL 등 타 DB 대비, 데이터 무결성/SQL 표준/고급 기능(윈도우 함수, JSON, 트랜잭션 등)에서 우위
        - Airflow, MLflow, Feast 등 주요 MLOps 솔루션 공식 지원 및 최적화
        - 실무 MLOps에서 복잡한 쿼리, 트랜잭션, 메타 관리에 최적
    - **S3 병행 이유**
        - 대용량, 바이너리, 장기 보관 데이터(PostgreSQL 한계) → 비용 효율성과 확장성 최고의 오브젝트 스토리지
        - MLflow/Feast/분석에서 S3 지원 및 연동 표준

### **[2] Feature Store 관리 (Feast)**

- **목표:** 전처리·특징 엔지니어링·피처 등록/관리 자동화
- **순서:**
    1. 데이터 엔지니어링 Task 후, 전처리/특징 추출 스크립트 실행
    2. Feast Feature Store(Feast Core/Redis 컨테이너)에 피처 등록
    3. Feast 오프라인 저장소로 **S3** 연동(대용량 피처 저장)
    4. 메타데이터(PostgreSQL)와 연동해 피처 정의/이력 관리
- **컨테이너 구조:**
    - `feast-core`, `feast-redis`, `feast-web`
    - Feast CLI/SDK 호출 Task는 임시 컨테이너로 실행
    - **Feast Core/Redis/Web 컨테이너**
        - **역할:**
            - 피처 스토어 엔진(Core), 온라인 피처(Serving)는 Redis, 관리 UI(Web)
        - **입출력 흐름:**
            - Feast CLI/SDK 호출 컨테이너, Airflow Worker Task 등에서
                
                정제된 피처를 등록/업데이트
                
            - 오프라인 피처: S3로 내보냄(Feast Core → S3)
            - 온라인 피처: Redis에 저장(Feast Core → Redis)
            - 피처 조회: FastAPI, 모델 학습 컨테이너가 실시간 요청
    - **수명:**
        - 상시 운영(Core/Redis/Web)
- 선택 이유
    - **Feast 선택 이유**
        - 엔드투엔드 MLOps에서 오픈소스, 경량 운영, 데이터/플랫폼 독립성 강점
        - Hopsworks, Tecton 등 대비 팀 규모/실습/운영 복잡도 낮고 비용 없음
        - 학습/서빙 간 피처 일관성 보장, 실무 적용 다수
    - **S3(오프라인), Redis(온라인) 분리 이유**
        - Feast 설계 표준: S3(대용량/배치 피처), Redis(저지연 실시간 피처)

### **[3] 데이터 분석, 모델 학습/평가**

- **목표:** 데이터 탐색, 모델링 실험, 학습, 성능 검증
- **순서:**
    1. JupyterLab/노트북 환경에서 데이터 탐색
    2. 모델 코드/학습 스크립트(주피터/CLI)를 컨테이너에서 실행
    3. MLflow Tracking Server(컨테이너)에 파라미터/지표 기록
    4. 학습된 모델은 MLflow에 아티팩트로 저장
    5. 필요시 S3에도 모델 아티팩트 백업
- **컨테이너 구조:**
    - `jupyterlab`
    - `ml-model-train`, `ml-eval` Task용 임시 컨테이너
    - 상시: MLflow Tracking Server
    - **MLflow Tracking Server 컨테이너**
        - **역할:**
            - 실험(실행) 메타, 모델, 결과, 로그 등 통합 관리
            - 아티팩트(모델, 시각화 파일)는 S3로 저장 연동
        - **입출력 흐름:**
            - 모델 학습/평가 컨테이너, FastAPI 서빙 컨테이너 등이
                
                API로 실험/아티팩트 기록/조회
                
            - Backend Store(PostgreSQL), Artifact Store(S3)로 연동
        - **수명:**
            - 상시 운영
- 선택 이유
    - **MLflow 선택 이유**
        - 실험, 파라미터, 결과, 아티팩트, 레지스트리까지 엔드투엔드 관리(업계 표준)
        - S3/PostgreSQL 등 확장형 백엔드 지원
        - 실무와 대회/교육 현장서 가장 널리 활용
    - **JupyterLab/컨테이너 분리 이유**
        - 개발/학습 환경을 도커화로 격리, 재현성과 충돌 방지

### **[4] ML Metadata Store & Model Registry**

- **목표:** 모델 실험/성과/아티팩트/버전 통합 관리
- **순서:**
    1. 모든 실험 데이터(파라미터, 지표, 태그 등)는 PostgreSQL(Mlflow Backend)
    2. 모델 파일, 시각화 결과 등은 S3(Mlflow Artifact Store)에 저장
    3. Staging/Production 레지스트리 단계, 배포 후보 모델 관리
- 선택 이유
    - **PostgreSQL+S3 조합 이유**
        - 메타데이터는 PostgreSQL, 대용량 아티팩트(모델 등)는 S3로 저장해야 각 장점 극대화
    - **MLflow 레지스트리 이유**
        - 오픈소스 표준, CI/CD 연계, Production 전환 자동화에 적합

### **[5] Airflow Worker 역할**

- **컨테이너 구조:**
    - **Airflow Worker 컨테이너**
        - **역할:**
            - Airflow Scheduler(서버2)의 Task Queue를 받아
                
                실제 데이터 수집, 전처리, 모델 학습 등 각종 작업 실행
                
        - **입출력 흐름:**
            - Airflow DAG에 정의된 Task 실행
            - 필요시 GHCR에서 이미지 pull → 임시 작업 컨테이너로 run
            - Task 종료 시 임시 컨테이너 자동 소멸
        - **수명:**
            - Worker는 상시 실행,
            - Task 컨테이너는 Task 실행 시 동적 생성/종료
- 선택 이유
    - **Airflow Worker 컨테이너화 이유**
        - 워크로드 분산, 장애시 자동 재시작, Task별 분리 실행이 용이

### **[6] 컨테이너 구성**

- 상시 컨테이너: PostgreSQL, Feast(Core/Redis/Web), MLflow Tracking Server, Airflow Worker
- 임시 컨테이너: 데이터 추출/전처리/피처엔지니어링/모델 학습 등 각 Task별 도커 이미지 기반 임시 컨테이너
    - **임시 Task 컨테이너: `data-extract`, `data-preprocess`, `ml-train`, `ml-eval` 등**
    - **역할:**
        - 각 파이프라인 단계의 실질 작업 실행 (ETL, 피처엔지니어링, 학습, 평가 등)
    - **입출력 흐름:**
        - 입력: S3/DB/Feast 등에서 원본 데이터/피처 fetch
        - 작업 수행
        - 출력: DB/S3/Feast/MLflow로 결과 저장
        - 로그: Kafka/Logstash로 전송
    - **수명:**
        - 작업 시작 시 자동 생성,
        - 작업 종료 후 자동 소멸
        - Task 실패 시 재시도(재생성) 가능
- **JupyterLab 컨테이너**
    - **역할:**
        - 탐색적 데이터 분석, 코드 테스트, 시각화
    - **입출력 흐름:**
        - 사용자 웹브라우저 ↔ 컨테이너 내 노트북
        - 데이터 로딩: DB/S3/Feast
        - 결과 저장: S3, MLflow, Feast
    - **수명:**
        - 실험/분석 중 상시 운영(혹은 필요시 run/stop)

---

### **2️⃣ 서버 2: 오케스트레이션 & 서빙 서버 (Control Tower)**

### **[1] CI/CD (GitHub Actions 중심)**

- **목표:** 코드/파이프라인 자동화, Docker 이미지 빌드/배포, Airflow DAG/서빙 앱 자동 관리
- **순서:**
    1. 모든 소스 코드, Dockerfile, 워크플로우 YAML은 GitHub에서 관리
    2. 코드(Push/PR) 이벤트 발생 → GitHub Actions CI 트리거
    3. CI: 단위/통합 테스트 후 도커 이미지 빌드(Preprocess/Train/Serve 등)
    4. GHCR/DockerHub로 이미지 푸시
    5. CD: DAG, 서빙 앱 코드/이미지 변경 감지 시, SSH로 서버2 접속
    6. Airflow DAG 파일 복사(`dags/` 디렉토리), 컨테이너 재시작
    7. 서빙 Docker 이미지 Pull, 구버전 컨테이너 중지/삭제, 신규 컨테이너 run
- **컨테이너 구조:**
    - GitHub Actions는 외부 서비스, 이 서버엔 결과물 배포(SSH 등)
    - Docker 이미지 배포/서빙용 컨테이너 run
- 선택 이유
    - **GitHub Actions 선택 이유**
        - GitHub 코드 저장소와 완벽 통합, 추가 인프라 불필요, 커뮤니티 액션 활용 용이
        - Jenkins/ArgoCD 등 대비 복잡성/유지보수/비용 최소화, 팀 협업에 최적
    - **Dockerfile 빌드/배포 자동화 이유**
        - 일관된 환경, 테스트/재현성/운영 효율성 보장

### **[2] Airflow (Webserver/Scheduler)**

- **목표:** 전체 MLOps Workflow 오케스트레이션 및 DAG 스케줄링/모니터링
- **순서:**
    1. DAG 정의 및 관리 (GitHub, 자동 배포)
    2. Scheduler: 실행 시점 결정, Task Queueing
    3. Webserver: UI 제공, DAG 관리/상태 확인
    4. 각 Task는 서버1의 Airflow Worker로 분배
- **컨테이너 구조:**
    - `airflow-webserver`, `airflow-scheduler`
    - **Airflow Webserver/Scheduler 컨테이너**
        - **역할:**
            - Webserver: DAG 상태 UI/관리
            - Scheduler: 실행 시점 결정, Worker(Task) 분배
        - **입출력 흐름:**
            - GitHub Actions/CD 워크플로우에서 DAG 파일 자동 배포
            - 사용자는 Webserver(포트 노출)로 DAG/Task 상태 실시간 모니터링
            - Scheduler는 Task를 서버1의 Worker에 Queue로 전달
        - **상태 점검 (Health Check)**:
            - Airflow Webserver에 `/health` 엔드포인트를 노출하여 서비스의 정상 동작 여부를 외부에서 확인할 수 있도록 구현합니다.
            - **서버 3의 Prometheus**는 이 `/health` 엔드포인트를 주기적으로 호출(Scraping)하여 Airflow 서비스 다운 등 이상 상황을 즉각 감지하고 Alertmanager를 통해 경고를 보냅니다.
        - **수명:**
            - 상시 운영
- 선택 이유
    - **Airflow 선택 이유**
        - 워크플로우/DAG/스케줄 관리, 재시도/로깅/의존성/분기 등 표준화
        - Kubeflow 등 대안 대비 구축/운영/학습/시각화 편의성 우위

### **[3] 모델 서빙/배포(FastAPI)**

- **목표:** 학습된 모델을 API 형태로 서빙, 실시간 예측 서비스 제공
- **순서:**
    1. GitHub Actions에서 모델 서빙용 Docker 이미지 빌드/배포
        - `서빙 코드 변경`: FastAPI 애플리케이션의 소스 코드가 변경되었을 때 (GitHub Push)
        - `새 모델 승인`: **서버 1의 MLflow Model Registry에서 새로운 모델 버전이 'Production' 단계로 승격되었을 때** (Webhook 트리거)
    2. CD 워크플로우로 SSH 접속 → 기존 컨테이너 중지/삭제, 신규 컨테이너 run
    3. FastAPI 컨테이너가 외부 Prediction API 요청 처리
    4. 필요시 Feast에서 실시간 피처 Fetch, 최신 모델로 예측 반환
- **컨테이너 구조:**
    - `fastapi-serve`
    - **FastAPI 서빙 컨테이너**
        - **역할:**
            - 실시간/배치 예측 API 제공
            - 서빙 컨테이너는 모델 아티팩트(Mlflow/S3)와 연동
            - CD 단계마다 최신 이미지로 자동 교체(run/pull)
        - **입출력 흐름:**
            - 클라이언트(사용자, 다른 서비스 등)에서 HTTP 요청 수신
            - 요청 시: Feast(서버1)에서 피처 fetch, MLflow/S3에서 모델 fetch
            - 예측 후 응답 반환
            - 로그: Kafka/Logstash 등으로 송신
        - **배포 플로우:**
            - CD 워크플로우(예: 모델 업데이트)로 새 이미지 Pull, 기존 컨테이너 Stop/Remove, 새 컨테이너 Run
        - **상태 점검 (Health Check)**:
            - FastAPI 앱 내에 `/health` 엔드포인트를 구현하여, API 서버가 정상적으로 요청을 처리할 수 있는 상태인지 외부에 노출합니다.
            - **서버 3의 Prometheus**가 이 엔드포인트를 주기적으로 점검하여 API 서버의 장애를 실시간으로 감지하고 즉시 경고를 발생시킵니다.
        - **수명:**
            - 상시 운영, 신규 모델 배포 시 자동 교체
- 선택 이유
    - **FastAPI 선택 이유**
        - 비동기, Python/ML 친화, 도커화, API문서 자동화(팀 내외 협업/테스트 최적)
        - Flask, Django, TF Serving 등 대안보다 실무 MLOps에 최적화

### **[4] 배포 및 유지보수 자동화**

- CD 실패/성공 알림, 상태 점검(Health Check), 무중단 배포 고려
- 선택 이유
    - **CI/CD 자동화 선택 이유**
        - 배포/테스트/롤백 전 과정 자동화, 팀 생산성/신뢰성 극대화

---

### **3️⃣ 서버 3: 모니터링 & 이벤트 서버 (Nervous System)**

### **[1] Kafka (이벤트 스트리밍)**

- **목표:** 데이터 파이프라인, 모델 서빙 등 전반의 로그/이벤트 실시간 스트림 처리
- **순서:**
    1. Airflow, FastAPI, 기타 서비스에서 Kafka Producer로 로그/이벤트 전송
    2. Kafka Consumer(Logstash, Alertmanager 등)로 실시간 데이터 소비 및 전달
- 컨테이너 구조
    - **Kafka 컨테이너**
        - **역할:**
            - 각종 로그/이벤트 스트림 처리(버퍼링, 실시간 전달)
        - **입출력 흐름:**
            - 데이터/모델/서빙 컨테이너에서 Producer로 이벤트/로그 발행
            - Logstash/Alertmanager 등 Consumer가 실시간 데이터 수신
        - **수명:**
            - 상시 운영
- 선택 이유
    - **Kafka 선택 이유**
        - 대용량/실시간 이벤트 처리, 로그/데이터 스트림, 확장성 표준
        - AWS Kinesis, RabbitMQ 등 대비 오픈소스 생태계, 운영사례/도구 연계 풍부

### **[2] Elastic Stack(ELK) (로그 분석/시각화)**

- **목표:** 분산 로그 중앙집중화, 빠른 검색/시각화, 실시간 상태 모니터링
- **순서:**
    1. Logstash가 Kafka 등에서 로그 수집
    2. Elasticsearch에 저장/인덱싱
    3. Kibana로 대시보드/검색/이상징후 탐지
- 컨테이너 구조
    - **Elastic Stack (Elasticsearch, Logstash, Kibana) 컨테이너**
        - **Elasticsearch:**
            - Kafka/Logstash에서 수집한 로그/지표 저장, 인덱싱
        - **Logstash:**
            - Kafka 등에서 실시간 로그 수집/정제/전송
        - **Kibana:**
            - 웹 UI로 검색/대시보드/알림 등 시각화
        - **입출력 흐름:**
            - Logstash가 Kafka→Elasticsearch 전달
            - Kibana가 Elasticsearch 데이터 조회/시각화
        - **수명:**
            - 상시 운영
- 선택 이유
    - **ELK 선택 이유**
        - 분산 로그 중앙집중화, 실시간 분석, 검색, 시각화에 업계 표준
        - Splunk 등 상용 대안 대비 비용/유연성/오픈소스 생태계 우위

### **[3] Prometheus/Grafana (성능 메트릭/대시보드)**

- **목표:** 시스템/애플리케이션 지표 수집 및 실시간 대시보드 구축
- **순서:**
    1. Exporter/Agent가 각 서버/컨테이너 메트릭 수집(Prometheus)
    2. Grafana로 대시보드 시각화(모델 성능, API 응답, 피처 신선도 등)
    3. Alertmanager가 임계치 이상 감지시 알람(Webhook, Slack 등) 발송
- 컨테이너 구조
    - **Prometheus & Grafana 컨테이너**
        - **Prometheus:**
            - 각 서버/컨테이너의 Exporter로부터 메트릭 수집, 상태 감시
        - **Grafana:**
            - Prometheus/Elasticsearch 등에서 메트릭을 받아 대시보드로 시각화
        - **입출력 흐름:**
            - Exporter(각 서버/컨테이너)가 메트릭 push/pull
            - Grafana가 Prometheus 등에서 데이터 fetch, 시각화
        - **수명:**
            - 상시 운영
- 선택 이유
    - **Prometheus 선택 이유**
        - 시스템/앱/컨테이너 메트릭 통합, 모니터링 자동화, Kubernetes/도커 등 연계 표준
    - **Grafana 선택 이유**
        - 실시간 대시보드, Alert, 다양한 데이터 소스 연동(Elastic, Prometheus 등)
    - **Alertmanager 연계**
        - 자동화 트리거(Webhook) 및 즉각적 장애 알림 가능

### **[4] Trigger(재학습/재배포 등 이벤트 트리거)**

- **목표:** 성능 저하/오류 감지 시 자동 재학습/배포 파이프라인 실행
- **순서:**
    1. Prometheus Alertmanager, Kibana 등에서 이벤트 감지
    2. GitHub Actions Webhook 트리거(파이프라인 재실행, Airflow DAG 트리거 등)
- 컨테이너 구조
    - **Alertmanager 컨테이너**
        - **역할:**
            - Prometheus로부터 경고/알림 이벤트 수신, Webhook 등으로 전달
        - **입출력 흐름:**
            - 임계치 초과/이상 감지 시 알림(Webhook, Slack 등) 전송
            - 필요시 GitHub Actions 워크플로우(재학습, 재배포 등) 트리거
        - **수명:**
            - 상시 운영
- 선택 이유
    - **Prometheus/Kibana 트리거 연계 이유**
        - 성능 저하/장애시 즉시 재학습/배포 자동화, 서비스 품질 보장

### **[5] 컨테이너 구성**

- Kafka, Zookeeper, Elasticsearch, Logstash, Kibana, Prometheus, Grafana, Alertmanager
    
    모두 각각 독립 컨테이너로 상시 실행
    

---

## **3. 전체 파이프라인 연결 구조 (서버-컨테이너-서비스 흐름)**

- **서버1**: 데이터 수집/가공→피처 추출→모델 학습/실험→MLflow 아티팩트 저장→Feast/S3 등록
    - 모든 Task별 Docker 컨테이너화, ML 메타/아티팩트 관리
- **서버2**: CI/CD 워크플로우 실행→Airflow DAG/서빙 앱 자동 배포→FastAPI 모델 API 운영
    - Airflow 오케스트레이션, API 서빙 컨테이너 자동 교체
- **서버3**: 로그/이벤트/지표 실시간 수집→Elastic Stack 시각화→Prometheus/Grafana 성능 대시보드→Alert/Trigger
    - 모든 로그/지표/알림 처리 컨테이너화

<aside>
💡

### **컨테이너 전체 흐름 요약**

- **파이프라인 시작:**
    
    Airflow Scheduler → Worker(Task) → 임시 Task 컨테이너 생성/실행
    
- **데이터/모델 이동:**
    
    Task 컨테이너 ↔ PostgreSQL/Feast/S3/MLflow
    
- **서빙:**
    
    FastAPI 컨테이너가 모델+피처 fetch, 예측 API 제공
    
- **로그/모니터링:**
    
    모든 컨테이너의 로그/이벤트/메트릭이 Kafka/Logstash/Prometheus 등으로 자동 수집
    
    → Elastic Stack/Grafana에서 시각화/분석, Alertmanager로 알림 및 트리거
    
- **CD/자동화:**
    
    GitHub Actions가 서버2에 DAG, 서빙앱, 이미지 자동 배포
    
    - **Redis**
        - Feast 온라인 피처 서비스
        - 저지연 실시간 피처 제공(Feast 공식 조합)
    
    배포 시 컨테이너 교체/재시작 자동화
    
- **임시 컨테이너:**
    
    Task별 단위 작업(ETL, 피처엔지니어링, 학습 등)은
    
    **GHCR에서 이미지 Pull → 컨테이너 Run → 작업 종료 시 컨테이너 Stop/Remove**
    
    (실패시 재시도/장애 격리 용이)
    
</aside>

---

## **4. 데이터 저장소/아티팩트/메타 관리**

- **PostgreSQL**:
    - Airflow, Feast, MLflow의 메타데이터(상태, 정의, 실험이력 등) 저장
    - 정형 데이터(관계형 저장이 필요한 경우)
    - Airflow/MLflow/Feast 공식 지원 메타스토리지, 정형 데이터/트랜잭션 강점
- **S3**:
    - Feast 오프라인 피처 데이터
    - MLflow 모델 아티팩트(대용량, 바이너리)
    - 원본 Raw 데이터 아카이빙
    - 대용량 아티팩트, 장기보관, 파일/분석/백업, 비용·확장성 최적
- **비교 설명**:
    - PostgreSQL만 단독 사용시, 대용량 파일/배치 작업/비용 등 한계
    - S3와 병행 시 정형+비정형, OLTP+OLAP, 비용·성능·확장 모두 최적

---

## **5. 보안 및 운영관리 및 장애대응**

- 각 서버 간 최소 권한 네트워크/방화벽
- SSH 키, 시크릿, 환경 변수 관리 강화(GitHub Secrets, AWS SSM 등)
    - 환경별 Secret 관리 방안
        - **로컬 개발:** `.env` 파일을 활용하여 `docker-compose.yml`에서 환경 변수 주입
        - **CI/CD (GitHub Actions):** `GitHub Secrets`에 API 키, DB 비밀번호 등을 저장하여 워크플로우에서 안전하게 사용
        - **런타임 (AWS EC2 서버):** `AWS Secrets Manager` 또는 `SSM Parameter Store`를 사용하여 서버에서 실행되는 컨테이너에 런타임 시크릿을 안전하게 전달
- 도커/OS 업데이트 자동화, 장애/오류 발생시 롤백 시나리오 준비

<aside>
💡

### 장애 대응/운영 고급 예시

- **모델 학습 Task 실패:**
    
    Airflow DAG에서 모델 학습 Task가 실패할 경우,
    
    Airflow는 자동 재시도 3회 수행 후에도 실패 시
    
    Alertmanager가 Slack/Webhook으로 알림을 전송하고,
    
    담당자가 확인 후 롤백/재실행 조치 가능
    
- **PostgreSQL 장애:**
    
    PostgreSQL에 단일 장애가 발생해도
    
    S3/Redis를 통해 일부 기능(피처 서빙/모델 배포)은
    
    지속적으로 유지됨(전체 서비스 무중단 운영 설계)
    
</aside>

---

## **6. (참고) 업무 분장/역할 예시**

- **서버1 담당:** 데이터 엔지니어, ML 엔지니어
- **서버2 담당:** DevOps, MLOps 담당, 백엔드 엔지니어
- **서버3 담당:** SRE, 데이터 분석가, 인프라 엔지니어

---

## **7. 실제 운영/배포 흐름 요약**

1. **서버1**:
    - 데이터 파이프라인/피처 엔지니어링/모델 학습 →
        
        Airflow Worker가 Docker Task로 실행,
        
        결과/메타는 PostgreSQL+S3+Feast/MLflow로 분산 관리
        
    - **각 도구는 실무 표준, 재현성/확장성/협업/유지보수 관점에서 검증된 이유로 선정**
2. **서버2**:
    - 코드/DAG/모델서빙 앱 등 GitHub Actions 기반 CI/CD 자동화로 배포
    - Airflow(Webserver/Scheduler), FastAPI(서빙)는
        
        표준화된 도커 컨테이너로 운영,
        
        자동/수동 배포 및 롤백 지원
        
3. **서버3**:
    - Kafka/ELK/Prometheus/Grafana 컨테이너 운영,
        
        실시간 로그/이벤트/지표  중앙집중 수집,
        
        시각화, Alert 및 재학습,
        
        Alertmanager로 트리거(재학습 등) 자동화
        
    - **모든 선택은 비용, 성능, 운영성, 실무 표준성 고려 결과**

---

# ✅ **PRD 문서 결론**

- **서버 1**은 데이터/모델의 ‘작업장’
- **서버 2**는 전체 ‘컨트롤 타워’ 및 ‘서비스 게이트’
- **서버 3**은 실시간 ‘감시자’ 및 ‘자동화 트리거러’
    
    로써,
    
    각각의 역할을 **도커 기반 격리**로 운영하며,
    
    **GitHub Actions CI/CD**가 전 서버를 연결하는 배포/자동화의 중심축 역할을 합니다.
